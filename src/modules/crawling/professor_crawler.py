"""
êµìˆ˜ ë° ì§ì› ì •ë³´ í¬ë¡¤ëŸ¬
"""
from typing import List, Tuple, Optional
from bs4 import BeautifulSoup
from .base_crawler import BaseCrawler
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from config import CrawlerConfig
from utils import korean_to_iso8601


class ProfessorCrawler(BaseCrawler):
    """ì •êµìˆ˜ í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__(
            board_type='professor',
            base_url=CrawlerConfig.BASE_URLS['professor']
        )

    def extract_from_url(self, url: str) -> Optional[Tuple[str, str, any, any, str, str]]:
        """
        ë‹¨ì¼ URLì´ ì•„ë‹Œ í˜ì´ì§€ ì „ì²´ êµìˆ˜ ëª©ë¡ì„ í¬ë¡¤ë§í•˜ë¯€ë¡œ ì‚¬ìš© ì•ˆ í•¨
        """
        return None

    def crawl_all(self) -> List[Tuple[str, str, any, any, str, str]]:
        """
        êµìˆ˜ ì •ë³´ ì „ì²´ í¬ë¡¤ë§ (í˜ì´ì§€ ê¸°ë°˜)

        Returns:
            [(title, text, image_list, attachment_list, date, url), ...] ë¦¬ìŠ¤íŠ¸
        """
        all_data = []

        print(f"\n{'='*80}")
        print(f"ğŸŒ {self.board_type.upper()} í¬ë¡¤ë§ ì‹œì‘")
        print(f"{'='*80}\n")

        try:
            response = self.fetch_with_retry(self.base_url)
            if response is None:
                return all_data

            soup = BeautifulSoup(response.text, "html.parser")

            # êµìˆ˜ ì •ë³´ê°€ ë‹´ê¸´ ìš”ì†Œë“¤ ì„ íƒ
            dr_div = soup.find("div", id="dr")
            if not dr_div:
                print("âš ï¸  êµìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return all_data

            professor_elements = dr_div.find_all("li")

            for professor in professor_elements:
                # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_element = professor.find("div", class_="dr_img")
                if image_element:
                    img_tag = image_element.find("img")
                    image_content = img_tag["src"] if img_tag else "Unknown Image URL"
                else:
                    image_content = "Unknown Image URL"

                # ì´ë¦„ ì¶”ì¶œ
                name_element = professor.find("div", class_="dr_txt")
                if name_element:
                    h3_tag = name_element.find("h3")
                    title = h3_tag.get_text(strip=True) if h3_tag else "Unknown Name"
                else:
                    title = "Unknown Name"

                # ì—°ë½ì²˜ì™€ ì´ë©”ì¼ ì¶”ì¶œ
                contact_info = professor.find("div", class_="dr_txt")
                if contact_info:
                    dd_tags = contact_info.find_all("dd")
                    contact_number = dd_tags[0].get_text(strip=True) if len(dd_tags) > 0 else "Unknown Contact Number"
                    email = dd_tags[1].get_text(strip=True) if len(dd_tags) > 1 else "Unknown Email"
                else:
                    contact_number = "Unknown Contact Number"
                    email = "Unknown Email"

                text_content = f"{title}, {contact_number}, {email}"

                # ë‚ ì§œì™€ URL ì„¤ì • (êµìˆ˜ ì •ë³´ëŠ” ê¸°ì¤€ì¼ë¡œ í†µì¼)
                date = korean_to_iso8601("ì‘ì„±ì¼24-01-01 00:00")

                prof_url_element = professor.find("a")
                prof_url = prof_url_element["href"] if prof_url_element else "Unknown URL"

                # ë°ì´í„° ì¶”ê°€ (ì´ë¯¸ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ, ì²¨ë¶€íŒŒì¼ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
                image_list = [image_content] if image_content != "Unknown Image URL" else []
                all_data.append((title, text_content, image_list, [], date, prof_url))

        except Exception as e:
            print(f"âŒ êµìˆ˜ ì •ë³´ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        print(f"\n{'='*80}")
        print(f"âœ… {self.board_type.upper()} í¬ë¡¤ë§ ì™„ë£Œ! {len(all_data)}ê°œ ìˆ˜ì§‘ë¨")
        print(f"{'='*80}\n")

        return all_data


class GuestProfessorCrawler(BaseCrawler):
    """ì´ˆë¹™êµìˆ˜ í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__(
            board_type='guest_professor',
            base_url=CrawlerConfig.BASE_URLS['guest_professor']
        )

    def extract_from_url(self, url: str) -> Optional[Tuple[str, str, any, any, str, str]]:
        """ì‚¬ìš© ì•ˆ í•¨"""
        return None

    def crawl_all(self) -> List[Tuple[str, str, any, any, str, str]]:
        """ì´ˆë¹™êµìˆ˜ ì •ë³´ ì „ì²´ í¬ë¡¤ë§"""
        all_data = []

        print(f"\n{'='*80}")
        print(f"ğŸŒ {self.board_type.upper()} í¬ë¡¤ë§ ì‹œì‘")
        print(f"{'='*80}\n")

        try:
            response = self.fetch_with_retry(self.base_url)
            if response is None:
                return all_data

            soup = BeautifulSoup(response.text, "html.parser")

            # êµìˆ˜ ì •ë³´ê°€ ë‹´ê¸´ ìš”ì†Œë“¤ ì„ íƒ
            student_div = soup.find("div", id="Student")
            if not student_div:
                print("âš ï¸  ì´ˆë¹™êµìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return all_data

            professor_elements = student_div.find_all("li")

            for professor in professor_elements:
                # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_element = professor.find("div", class_="img")
                if image_element:
                    img_tag = image_element.find("img")
                    image_content = img_tag["src"] if img_tag else "Unknown Image URL"
                else:
                    image_content = "Unknown Image URL"

                # ì´ë¦„ ì¶”ì¶œ
                name_element = professor.find("div", class_="cnt")
                if name_element:
                    name_div = name_element.find("div", class_="name")
                    title = name_div.get_text(strip=True) if name_div else "Unknown Name"
                else:
                    title = "Unknown Name"

                # ì—°ë½ì²˜ì™€ ì´ë©”ì¼ ì¶”ì¶œ
                contact_place_element = professor.find("div", class_="dep")
                contact_place = contact_place_element.get_text(strip=True) if contact_place_element else "Unknown Contact Place"

                email_element = professor.find("dl", class_="email")
                if email_element:
                    dd_tag = email_element.find("dd")
                    if dd_tag:
                        a_tag = dd_tag.find("a")
                        email = a_tag.get_text(strip=True) if a_tag else "Unknown Email"
                    else:
                        email = "Unknown Email"
                else:
                    email = "Unknown Email"

                # í…ìŠ¤íŠ¸ ë‚´ìš© ì¡°í•©
                text_content = f"ì„±í•¨(ì´ë¦„):{title}, ì—°êµ¬ì‹¤(ì¥ì†Œ):{contact_place}, ì´ë©”ì¼:{email}"

                # ë‚ ì§œì™€ URL ì„¤ì • (êµìˆ˜ ì •ë³´ëŠ” ê¸°ì¤€ì¼ë¡œ í†µì¼)
                date = korean_to_iso8601("ì‘ì„±ì¼24-01-01 00:00")
                prof_url = self.base_url

                # ë°ì´í„° ì¶”ê°€ (ì´ë¯¸ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ, ì²¨ë¶€íŒŒì¼ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
                image_list = [image_content] if image_content != "Unknown Image URL" else []
                all_data.append((title, text_content, image_list, [], date, prof_url))

        except Exception as e:
            print(f"âŒ ì´ˆë¹™êµìˆ˜ ì •ë³´ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        print(f"\n{'='*80}")
        print(f"âœ… {self.board_type.upper()} í¬ë¡¤ë§ ì™„ë£Œ! {len(all_data)}ê°œ ìˆ˜ì§‘ë¨")
        print(f"{'='*80}\n")

        return all_data


class StaffCrawler(BaseCrawler):
    """ì§ì› í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__(
            board_type='staff',
            base_url=CrawlerConfig.BASE_URLS['staff']
        )

    def extract_from_url(self, url: str) -> Optional[Tuple[str, str, any, any, str, str]]:
        """ì‚¬ìš© ì•ˆ í•¨"""
        return None

    def crawl_all(self) -> List[Tuple[str, str, any, any, str, str]]:
        """ì§ì› ì •ë³´ ì „ì²´ í¬ë¡¤ë§"""
        all_data = []

        print(f"\n{'='*80}")
        print(f"ğŸŒ {self.board_type.upper()} í¬ë¡¤ë§ ì‹œì‘")
        print(f"{'='*80}\n")

        try:
            response = self.fetch_with_retry(self.base_url)
            if response is None:
                return all_data

            soup = BeautifulSoup(response.text, "html.parser")

            # ì§ì› ì •ë³´ê°€ ë‹´ê¸´ ìš”ì†Œë“¤ ì„ íƒ
            student_div = soup.find("div", id="Student")
            if not student_div:
                print("âš ï¸  ì§ì› ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return all_data

            staff_elements = student_div.find_all("li")

            for staff in staff_elements:
                # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_element = staff.find("div", class_="img")
                if image_element:
                    img_tag = image_element.find("img")
                    image_content = img_tag["src"] if img_tag else "Unknown Image URL"
                else:
                    image_content = "Unknown Image URL"

                # ì´ë¦„ ì¶”ì¶œ
                cnt_element = staff.find("div", class_="cnt")
                if cnt_element:
                    h1_tag = cnt_element.find("h1")
                    title = h1_tag.get_text(strip=True) if h1_tag else "Unknown Name"
                else:
                    title = "Unknown Name"

                # ì—°ë½ì²˜ ì¶”ì¶œ
                contact_number_element = staff.find("span", class_="period")
                contact_number = contact_number_element.get_text(strip=True) if contact_number_element else "Unknown Contact Number"

                # ì—°êµ¬ì‹¤ ìœ„ì¹˜, ì´ë©”ì¼, ë‹´ë‹¹ ì—…ë¬´ ì¶”ì¶œ
                contact_info = staff.find_all("dl", class_="dep")
                contact_place = contact_info[0].find("dd").get_text(strip=True) if len(contact_info) > 0 and contact_info[0].find("dd") else "Unknown Contact Place"

                email_dd = contact_info[1].find("dd") if len(contact_info) > 1 else None
                if email_dd:
                    email_a = email_dd.find("a")
                    email = email_a.get_text(strip=True) if email_a else "Unknown Email"
                else:
                    email = "Unknown Email"

                role_dd = contact_info[2].find("dd") if len(contact_info) > 2 else None
                role = role_dd.get_text(strip=True) if role_dd else "Unknown Role"

                # í…ìŠ¤íŠ¸ ë‚´ìš© ì¡°í•©
                text_content = f"ì„±í•¨(ì´ë¦„):{title}, ì—°ë½ì²˜(ì „í™”ë²ˆí˜¸):{contact_number}, ì‚¬ë¬´ì‹¤(ì¥ì†Œ):{contact_place}, ì´ë©”ì¼:{email}, ë‹´ë‹¹ì—…ë¬´:{role}"

                # ë‚ ì§œì™€ URL ì„¤ì • (êµìˆ˜ ì •ë³´ëŠ” ê¸°ì¤€ì¼ë¡œ í†µì¼)
                date = korean_to_iso8601("ì‘ì„±ì¼24-01-01 00:00")
                staff_url = self.base_url

                # ë°ì´í„° ì¶”ê°€ (ì´ë¯¸ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ, ì²¨ë¶€íŒŒì¼ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
                image_list = [image_content] if image_content != "Unknown Image URL" else []
                all_data.append((title, text_content, image_list, [], date, staff_url))

        except Exception as e:
            print(f"âŒ ì§ì› ì •ë³´ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        print(f"\n{'='*80}")
        print(f"âœ… {self.board_type.upper()} í¬ë¡¤ë§ ì™„ë£Œ! {len(all_data)}ê°œ ìˆ˜ì§‘ë¨")
        print(f"{'='*80}\n")

        return all_data
