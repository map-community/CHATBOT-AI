"""
BM25 Retriever
BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ë¬¸ì„œ ê²€ìƒ‰ í´ë˜ìŠ¤
"""

import numpy as np
from rank_bm25 import BM25Okapi
from typing import List, Tuple
import logging

logger = logging.getLogger(__name__)


class BM25Retriever:
    """
    BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” í´ë˜ìŠ¤

    ì œëª©ê³¼ ë³¸ë¬¸ì„ ê²°í•©í•˜ì—¬ í† í°í™”í•˜ê³ , BM25 ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬
    ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    ê°œì„ ì‚¬í•­: ì œëª©ë¿ë§Œ ì•„ë‹ˆë¼ ë³¸ë¬¸ë„ ê²€ìƒ‰í•˜ì—¬ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ë„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """

    def __init__(self,
                 titles: List[str],
                 texts: List[str],
                 urls: List[str],
                 dates: List[str],
                 query_transformer,
                 similarity_adjuster,
                 k1: float = 1.5,
                 b: float = 0.75):
        """
        BM25Retriever ì´ˆê¸°í™”

        Args:
            titles: ë¬¸ì„œ ì œëª© ë¦¬ìŠ¤íŠ¸
            texts: ë¬¸ì„œ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸
            urls: ë¬¸ì„œ URL ë¦¬ìŠ¤íŠ¸
            dates: ë¬¸ì„œ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
            query_transformer: ì§ˆë¬¸ì„ ëª…ì‚¬ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (transformed_query)
            similarity_adjuster: ìœ ì‚¬ë„ë¥¼ ì¡°ì •í•˜ëŠ” í•¨ìˆ˜ (adjust_similarity_scores)
            k1: BM25 k1 íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 1.5)
            b: BM25 b íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 0.75)
        """
        self.titles = titles
        self.texts = texts
        self.urls = urls
        self.dates = dates
        self.query_transformer = query_transformer
        self.similarity_adjuster = similarity_adjuster
        self.k1 = k1
        self.b = b

        # BM25 ì¸ë±ìŠ¤ ìƒì„± (ì œëª© + ë³¸ë¬¸ ê²°í•©í•˜ì—¬ ê²€ìƒ‰)
        logger.info("ğŸ”„ BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘ (ì œëª©+ë³¸ë¬¸ ê²€ìƒ‰)...")
        self.tokenized_documents = [
            query_transformer(title + " " + text)
            for title, text in zip(titles, texts)
        ]
        self.bm25_index = BM25Okapi(self.tokenized_documents, k1=k1, b=b)
        logger.info(f"âœ… BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ ({len(titles)}ê°œ ë¬¸ì„œ, ì²¨ë¶€íŒŒì¼ ë‚´ìš© í¬í•¨)")

    def search(self,
               query_nouns: List[str],
               top_k: int = 25,
               normalize_factor: float = 24.0) -> Tuple[List[Tuple], np.ndarray]:
        """
        BM25 ê²€ìƒ‰ ìˆ˜í–‰

        Args:
            query_nouns: ê²€ìƒ‰ ì§ˆë¬¸ì˜ ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸
            top_k: ë°˜í™˜í•  ìƒìœ„ ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ê°’: 25)
            normalize_factor: ìœ ì‚¬ë„ ì •ê·œí™” íŒ©í„° (ê¸°ë³¸ê°’: 24.0)

        Returns:
            Tuple[List[Tuple], np.ndarray]:
                - ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (title, date, text, url)
                - ì¡°ì •ëœ ìœ ì‚¬ë„ ë°°ì—´
        """
        # BM25 ìœ ì‚¬ë„ ê³„ì‚°
        similarities = self.bm25_index.get_scores(query_nouns)

        # ìœ ì‚¬ë„ ì •ê·œí™”
        similarities = similarities / normalize_factor

        # ìœ ì‚¬ë„ ì¡°ì • (ì œëª©-ë³¸ë¬¸ ë§¤ì¹­, í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ë“±)
        adjusted_similarities = self.similarity_adjuster(
            query_nouns,
            self.titles,
            self.texts,
            similarities
        )

        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ì¶”ì¶œ (ë‚´ë¦¼ì°¨ìˆœ)
        top_indices = np.argsort(adjusted_similarities)[-top_k:][::-1]

        # ê²°ê³¼ ë¬¸ì„œ ìƒì„±
        results = [
            (self.titles[i], self.dates[i], self.texts[i], self.urls[i])
            for i in top_indices
        ]

        logger.debug(f"âœ… BM25 ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ë°˜í™˜")

        return results, adjusted_similarities

    def get_similarity_score(self, query_nouns: List[str], doc_index: int) -> float:
        """
        íŠ¹ì • ë¬¸ì„œì— ëŒ€í•œ BM25 ìœ ì‚¬ë„ ì ìˆ˜ ë°˜í™˜

        Args:
            query_nouns: ê²€ìƒ‰ ì§ˆë¬¸ì˜ ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸
            doc_index: ë¬¸ì„œ ì¸ë±ìŠ¤

        Returns:
            float: BM25 ìœ ì‚¬ë„ ì ìˆ˜
        """
        similarities = self.bm25_index.get_scores(query_nouns)
        return similarities[doc_index]

    def update_index(self,
                     titles: List[str],
                     texts: List[str],
                     urls: List[str],
                     dates: List[str]):
        """
        BM25 ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ë¬¸ì„œ ì¶”ê°€/ì‚­ì œ ì‹œ ì‚¬ìš©)

        Args:
            titles: ìƒˆë¡œìš´ ë¬¸ì„œ ì œëª© ë¦¬ìŠ¤íŠ¸
            texts: ìƒˆë¡œìš´ ë¬¸ì„œ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸
            urls: ìƒˆë¡œìš´ ë¬¸ì„œ URL ë¦¬ìŠ¤íŠ¸
            dates: ìƒˆë¡œìš´ ë¬¸ì„œ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ğŸ”„ BM25 ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")

        self.titles = titles
        self.texts = texts
        self.urls = urls
        self.dates = dates

        # ì œëª© + ë³¸ë¬¸ ê²°í•©í•˜ì—¬ ì¸ë±ìŠ¤ ìƒì„± (ì²¨ë¶€íŒŒì¼ ë‚´ìš© í¬í•¨)
        self.tokenized_documents = [
            self.query_transformer(title + " " + text)
            for title, text in zip(titles, texts)
        ]
        self.bm25_index = BM25Okapi(self.tokenized_documents, k1=self.k1, b=self.b)

        logger.info(f"âœ… BM25 ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(titles)}ê°œ ë¬¸ì„œ, ì²¨ë¶€íŒŒì¼ ë‚´ìš© í¬í•¨)")
