"""
Upstage API í´ë¼ì´ì–¸íŠ¸
Document Parse, OCR ë“± Upstage ì„œë¹„ìŠ¤ í†µí•©
"""
import os
import requests
import logging
from typing import Optional, Dict, List
from pathlib import Path
import time

logger = logging.getLogger(__name__)


class UpstageClient:
    """
    Upstage API í†µí•© í´ë¼ì´ì–¸íŠ¸

    ì§€ì› ê¸°ëŠ¥:
    - Document Parse: PDF, DOCX, HWP, PPTX ë“±
    - OCR: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - Vision: ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± (í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)
    """

    # Upstage Document Digitization API (í†µí•© ì—”ë“œí¬ì¸íŠ¸)
    # Document Parseì™€ OCR ëª¨ë‘ ì´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©, model íŒŒë¼ë¯¸í„°ë¡œ êµ¬ë¶„
    API_URL = "https://api.upstage.ai/v1/document-digitization"

    # ì§€ì› íŒŒì¼ íƒ€ì…
    SUPPORTED_DOCUMENT_TYPES = {
        '.pdf', '.docx', '.doc', '.pptx', '.ppt',
        '.hwp', '.xlsx', '.xls'
    }

    SUPPORTED_IMAGE_TYPES = {
        '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'
    }

    def __init__(self, api_key: Optional[str] = None, max_retries: int = 3):
        """
        Args:
            api_key: Upstage API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            max_retries: API ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
        """
        self.api_key = api_key or os.getenv('UPSTAGE_API_KEY')
        if not self.api_key:
            raise ValueError("UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.max_retries = max_retries
        self.headers = {
            "Authorization": f"Bearer {self.api_key}"
        }

    def parse_document_from_url(self, url: str) -> Optional[Dict]:
        """
        URLì—ì„œ ë¬¸ì„œë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  Document Parse APIë¡œ ì²˜ë¦¬

        Args:
            url: ë¬¸ì„œ URL

        Returns:
            {
                "text": "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                "html": "HTML í˜•ì‹",
                "elements": [...],  # êµ¬ì¡°í™”ëœ ìš”ì†Œë“¤
                "source_url": "..."
            }
            ì‹¤íŒ¨ ì‹œ None
        """
        try:
            logger.info(f"ğŸ“„ Document Parse ì‹œì‘: {url}")

            # URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ í›„ ì—…ë¡œë“œ
            try:
                # download.phpì˜ ê²½ìš° ì„¸ì…˜ ìœ ì§€ê°€ í•„ìš” (ë´‡ ì°¨ë‹¨ ìš°íšŒ)
                if 'download.php' in url:
                    from urllib.parse import urlparse, parse_qs

                    # URL íŒŒì‹±
                    parsed = urlparse(url)
                    params = parse_qs(parsed.query)

                    # ì„¸ì…˜ ìƒì„±
                    session = requests.Session()
                    session.headers.update({
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })

                    # ë² ì´ìŠ¤ URL
                    base_url = f"{parsed.scheme}://{parsed.netloc}"

                    # 1ë‹¨ê³„: ê²Œì‹œíŒ ë°©ë¬¸ (bo_tableë§Œ)
                    if 'bo_table' in params:
                        bo_table = params['bo_table'][0]
                        board_url = f"{base_url}/bbs/board.php?bo_table={bo_table}"
                        logger.info(f"ğŸ”— 1ë‹¨ê³„: ê²Œì‹œíŒ ë°©ë¬¸ - {board_url}")
                        session.get(board_url, timeout=30)

                    # 2ë‹¨ê³„: ê¸€ ë°©ë¬¸ (bo_table + wr_id)
                    if 'bo_table' in params and 'wr_id' in params:
                        bo_table = params['bo_table'][0]
                        wr_id = params['wr_id'][0]
                        post_url = f"{base_url}/bbs/board.php?bo_table={bo_table}&wr_id={wr_id}"
                        logger.info(f"ğŸ”— 2ë‹¨ê³„: ê¸€ ë°©ë¬¸ - {post_url}")
                        session.get(post_url, timeout=30)

                    # 3ë‹¨ê³„: ë‹¤ìš´ë¡œë“œ (ì„¸ì…˜ ìœ ì§€ ìƒíƒœ)
                    logger.info(f"ğŸ”— 3ë‹¨ê³„: íŒŒì¼ ë‹¤ìš´ë¡œë“œ - {url}")
                    file_response = session.get(url, timeout=30, allow_redirects=True)
                else:
                    # ì¼ë°˜ URLì€ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
                    file_response = requests.get(url, timeout=30, allow_redirects=True)

                if file_response.status_code != 200:
                    logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}")
                    return None

                # Content-Typeê³¼ Content-Dispositionì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                content_type = file_response.headers.get('Content-Type', '').lower()
                content_disposition = file_response.headers.get('Content-Disposition', '')

                logger.info(f"ğŸ“Š ì‘ë‹µ ì •ë³´: Content-Type={content_type}, Content-Disposition={content_disposition}")

                # ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: Content-Disposition > URL ê²½ë¡œ)
                filename = None

                # 1. Content-Disposition í—¤ë”ì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ (ê°€ì¥ ì‹ ë¢°ì„± ë†’ìŒ)
                if 'filename=' in content_disposition:
                    import re
                    # RFC 5987: filename*=UTF-8''encoded_filename ë˜ëŠ” filename="regular_filename"
                    match = re.search(r"filename\*=(?:UTF-8'')?([^;]+)|filename=([^;]+)", content_disposition)
                    if match:
                        encoded_filename = match.group(1)
                        regular_filename = match.group(2)

                        if encoded_filename:
                            # URL ë””ì½”ë”©
                            from urllib.parse import unquote
                            filename = unquote(encoded_filename).strip('"\'')
                        elif regular_filename:
                            filename = regular_filename.strip('"\'')

                # 2. URL ê²½ë¡œì—ì„œ ì¶”ì¶œ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°!)
                if not filename:
                    filename = Path(url).name
                    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±° (download.php?... â†’ download.php)
                    if '?' in filename:
                        filename = filename.split('?')[0]

                # 3. Content-Typeì—ì„œ í™•ì¥ì ìœ ì¶” (ìµœí›„ì˜ ìˆ˜ë‹¨)
                if not filename or filename == 'download.php' or not Path(filename).suffix:
                    type_to_ext = {
                        'application/pdf': '.pdf',
                        'application/msword': '.doc',
                        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
                        'application/x-hwp': '.hwp',
                        'application/haansofthwp': '.hwp',
                        'application/vnd.ms-powerpoint': '.ppt',
                        'application/vnd.openxmlformats-officedocument.presentationml.presentation': '.pptx'
                    }
                    for mime_type, ext in type_to_ext.items():
                        if mime_type in content_type:
                            filename = f"document{ext}"
                            break

                logger.info(f"ğŸ“„ ìµœì¢… íŒŒì¼ëª…: {filename}")

                # íŒŒì¼ í™•ì¥ì í™•ì¸
                file_ext = Path(filename).suffix.lower()

                # ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸
                supported_image_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/bmp', 'image/webp']
                is_image = (
                    any(t in content_type for t in supported_image_types) or
                    file_ext in self.SUPPORTED_IMAGE_TYPES
                )

                # ì´ë¯¸ì§€ íŒŒì¼ì´ë©´ OCRë¡œ ìë™ ì „í™˜
                if is_image:
                    logger.info(f"ğŸ“Š ì´ë¯¸ì§€ íŒŒì¼ ê°ì§€ ({file_ext}) - OCRë¡œ ì „í™˜")

                    # OCR API í˜¸ì¶œ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ ì‚¬ìš©)
                    files = {
                        "document": (filename, file_response.content)
                    }
                    data_param = {
                        "model": "document-parse",
                        "ocr": "auto"
                    }

                    for attempt in range(self.max_retries):
                        try:
                            response = requests.post(
                                self.API_URL,
                                headers=self.headers,
                                files=files,
                                data=data_param,
                                timeout=30
                            )

                            if response.status_code == 200:
                                result = response.json()
                                logger.info(f"ğŸ“Š OCR API ì‘ë‹µ í‚¤: {list(result.keys())}")

                                extracted_text = self._extract_text_from_response(result)

                                if extracted_text:
                                    logger.info(f"âœ… OCR ì„±ê³µ (ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼): {len(extracted_text)}ì ì¶”ì¶œ")
                                    return {
                                        "text": extracted_text,
                                        "html": result.get("content", {}).get("html", ""),
                                        "full_html": result.get("content", {}).get("html", ""),
                                        "elements": result.get("elements", []),
                                        "source_url": url
                                    }
                                else:
                                    logger.warning("âš ï¸  OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ (ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼)")
                                    return None
                            else:
                                logger.warning(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                        except Exception as e:
                            if attempt < self.max_retries - 1:
                                wait_time = 2 ** attempt
                                logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                                time.sleep(wait_time)
                            else:
                                logger.error(f"OCR ì‹¤íŒ¨ (ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼): {e}")
                                raise

                    return None

                # Content-Typeìœ¼ë¡œ ë¬¸ì„œ íƒ€ì… í™•ì¸
                supported_types = [
                    'application/pdf',
                    'application/msword',
                    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    'application/vnd.ms-powerpoint',
                    'application/vnd.openxmlformats-officedocument.presentationml.presentation',
                    'application/vnd.ms-excel',
                    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    'application/x-hwp',  # HWP
                    'application/haansofthwp',  # HWP
                ]

                # ë¬¸ì„œ íƒ€ì… í™•ì¸
                is_supported = (
                    any(t in content_type for t in supported_types) or
                    file_ext in self.SUPPORTED_DOCUMENT_TYPES
                )

                if not is_supported:
                    logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {content_type}, í™•ì¥ì: {file_ext}")
                    logger.warning(f"URL: {url}")
                    logger.warning(f"íŒŒì¼ëª…: {filename}")
                    return None

                # íŒŒì¼ëª…ì´ ê¸¸ë©´ ì¤„ì„
                display_name = filename if len(filename) <= 30 else f"{filename[:27]}..."
                logger.info(f"ğŸ“„ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {display_name}")

                # Upstage Document Parse API í˜¸ì¶œ (íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹)
                files = {
                    "document": (filename, file_response.content)
                }
                data = {
                    "model": "document-parse",  # í•„ìˆ˜!
                    "ocr": "auto"  # OCR ìë™ í™œì„±í™” (PDF ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ , í•„ìš”ì‹œ OCR)
                }

                for attempt in range(self.max_retries):
                    try:
                        response = requests.post(
                            self.API_URL,
                            headers=self.headers,
                            files=files,
                            data=data,
                            timeout=60
                        )

                        if response.status_code == 200:
                            result = response.json()

                            # ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                            logger.info(f"ğŸ“Š Document Parse API ì‘ë‹µ í‚¤: {list(result.keys())}")

                            # í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê³µì‹ ë¬¸ì„œ ì‘ë‹µ êµ¬ì¡° ì‚¬ìš©)
                            extracted_text = self._extract_text_from_response(result)

                            if extracted_text:
                                logger.info(f"âœ… Document Parse ì„±ê³µ: {len(extracted_text)}ì ì¶”ì¶œ")
                            else:
                                logger.warning(f"âš ï¸  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨. ì‘ë‹µ êµ¬ì¡°: {result}")

                            # RAGìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ HTML ë‘˜ ë‹¤ ë°˜í™˜
                            return {
                                "text": extracted_text,  # ê²€ìƒ‰ìš© ìˆœìˆ˜ í…ìŠ¤íŠ¸
                                "html": result.get("content", {}).get("html", ""),  # êµ¬ì¡° ë³´ì¡´ìš© HTML
                                "full_html": result.get("content", {}).get("html", ""),  # ì›ë³¸ HTML (ë³„ì¹­)
                                "markdown": result.get("content", {}).get("markdown", ""),  # Markdown (ìˆìœ¼ë©´)
                                "elements": result.get("elements", []),
                                "source_url": url
                            }
                        else:
                            logger.warning(f"Document Parse API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                    except Exception as e:
                        if attempt < self.max_retries - 1:
                            wait_time = 2 ** attempt
                            logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                            time.sleep(wait_time)
                        else:
                            logger.error(f"Document Parse ì‹¤íŒ¨: {e}")
                            raise

            except Exception as download_error:
                logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {download_error}")
                return None

            return None

        except Exception as e:
            logger.error(f"ë¬¸ì„œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {url} - {e}")
            return None

    def extract_text_from_image_url(self, url: str) -> Optional[Dict]:
        """
        ì´ë¯¸ì§€ URLì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            url: ì´ë¯¸ì§€ URL

        Returns:
            {
                "text": "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                "confidence": 0.95,
                "words": [...]
            }
            ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # Data URIëŠ” ì§§ê²Œ ë¡œê¹…
            if url.startswith('data:'):
                log_url = "Data URI (Base64 ì´ë¯¸ì§€)"
            else:
                log_url = url[:100] + "..." if len(url) > 100 else url
            logger.info(f"ğŸ–¼ï¸  OCR ì‹œì‘: {log_url}")

            # Data URI Scheme ì²˜ë¦¬ (data:image/png;base64,...)
            if url.startswith('data:'):
                try:
                    import base64
                    import re

                    logger.info("ğŸ“Š Data URI ê°ì§€ - Base64 ë””ì½”ë”© ì‹œì‘")

                    # Data URI íŒŒì‹±: data:[<mediatype>][;base64],<data>
                    match = re.match(r'data:([^;]+);base64,(.+)', url)
                    if not match:
                        logger.error("Data URI í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ (base64 ì¸ì½”ë”© í•„ìš”)")
                        return None

                    mime_type = match.group(1)  # image/png, image/jpeg ë“±
                    base64_data = match.group(2)

                    # MIME íƒ€ì… í™•ì¸
                    supported_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/bmp', 'image/webp']
                    if mime_type not in supported_types:
                        logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {mime_type}")
                        return None

                    # Base64 ë””ì½”ë”©
                    image_data = base64.b64decode(base64_data)
                    data_length = len(image_data)

                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    if data_length < 100:
                        logger.warning(f"ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë„ˆë¬´ ì‘ìŒ ({data_length} bytes)")
                        return None

                    # í™•ì¥ì ê²°ì •
                    ext_map = {
                        'image/jpeg': '.jpg',
                        'image/jpg': '.jpg',
                        'image/png': '.png',
                        'image/gif': '.gif',
                        'image/bmp': '.bmp',
                        'image/webp': '.webp'
                    }
                    extension = ext_map.get(mime_type, '.jpg')
                    filename = f"data_uri_image{extension}"

                    logger.info(f"ğŸ“Š ë””ì½”ë”© ì„±ê³µ: {mime_type}, {data_length} bytes")

                    # Upstage OCR API í˜¸ì¶œ
                    files = {
                        "document": (filename, image_data)
                    }
                    data_param = {
                        "model": "document-parse",
                        "ocr": "auto"
                    }

                    for attempt in range(self.max_retries):
                        try:
                            response = requests.post(
                                self.API_URL,
                                headers=self.headers,
                                files=files,
                                data=data_param,
                                timeout=30
                            )

                            if response.status_code == 200:
                                result = response.json()

                                # ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                                logger.info(f"ğŸ“Š OCR API ì‘ë‹µ í‚¤: {list(result.keys())}")

                                # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                extracted_text = self._extract_text_from_response(result)

                                if extracted_text:
                                    logger.info(f"âœ… OCR ì„±ê³µ (Data URI): {len(extracted_text)}ì ì¶”ì¶œ")

                                    # RAGìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ HTML ë‘˜ ë‹¤ ë°˜í™˜
                                    return {
                                        "text": extracted_text,
                                        "html": result.get("content", {}).get("html", ""),
                                        "full_html": result.get("content", {}).get("html", ""),
                                        "elements": result.get("elements", []),
                                        "source_url": "data_uri"  # Data URIëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ "data_uri"ë¡œ í‘œì‹œ
                                    }
                                else:
                                    logger.warning("âš ï¸  OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ (Data URI)")
                                    return None
                            else:
                                logger.warning(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                        except Exception as e:
                            if attempt < self.max_retries - 1:
                                wait_time = 2 ** attempt
                                logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                                time.sleep(wait_time)
                            else:
                                logger.error(f"OCR ì‹¤íŒ¨ (Data URI): {e}")
                                raise

                    return None

                except Exception as data_uri_error:
                    logger.error(f"Data URI ì²˜ë¦¬ ì˜¤ë¥˜: {data_uri_error}")
                    return None

            # ì¼ë°˜ HTTP/HTTPS URL ì²˜ë¦¬
            # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë¦¬ë‹¤ì´ë ‰íŠ¸ ë”°ë¼ê°€ê¸°!)
            try:
                file_response = requests.get(url, timeout=30, allow_redirects=True)
                if file_response.status_code != 200:
                    log_url = url[:100] + "..." if len(url) > 100 else url
                    logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {log_url}")
                    return None

                # Content-Type í™•ì¸
                content_type = file_response.headers.get('Content-Type', '').lower()
                content_disposition = file_response.headers.get('Content-Disposition', '')

                # ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: Content-Disposition > URL ê²½ë¡œ)
                filename = None

                # 1. Content-Disposition í—¤ë”
                if 'filename=' in content_disposition:
                    import re
                    match = re.search(r"filename\*=(?:UTF-8'')?([^;]+)|filename=([^;]+)", content_disposition)
                    if match:
                        encoded_filename = match.group(1)
                        regular_filename = match.group(2)

                        if encoded_filename:
                            from urllib.parse import unquote
                            filename = unquote(encoded_filename).strip('"\'')
                        elif regular_filename:
                            filename = regular_filename.strip('"\'')

                # 2. URL ê²½ë¡œ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°)
                if not filename:
                    filename = Path(url).name
                    if '?' in filename:
                        filename = filename.split('?')[0]

                # ì´ë¯¸ì§€ íƒ€ì… í™•ì¸
                supported_image_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/bmp', 'image/webp']
                file_ext = Path(filename).suffix.lower()

                is_image = (
                    any(t in content_type for t in supported_image_types) or
                    file_ext in self.SUPPORTED_IMAGE_TYPES
                )

                if not is_image:
                    log_url = url[:100] + "..." if len(url) > 100 else url
                    logger.warning(f"ì´ë¯¸ì§€ê°€ ì•„ë‹˜: {content_type}, í™•ì¥ì: {file_ext}, URL: {log_url}")
                    return None

                # íŒŒì¼ í¬ê¸° í™•ì¸ (ë„ˆë¬´ ì‘ìœ¼ë©´ ì†ìƒë˜ì—ˆì„ ê°€ëŠ¥ì„±)
                content_length = len(file_response.content)
                if content_length < 100:
                    log_url = url[:100] + "..." if len(url) > 100 else url
                    logger.warning(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ ({content_length} bytes): {log_url}")
                    return None

                # íŒŒì¼ëª…ì´ ê¸¸ë©´ ì¤„ì„
                display_name = filename if len(filename) <= 30 else f"{filename[:27]}..."
                logger.info(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {display_name}, {content_length} bytes")

                # Upstage OCR API í˜¸ì¶œ (íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹)
                # ì´ë¯¸ì§€ë„ document-parse ëª¨ë¸ë¡œ ì²˜ë¦¬ (ìë™ OCR)
                files = {
                    "document": (filename, file_response.content)
                }
                data = {
                    "model": "document-parse",  # í•„ìˆ˜! ì´ë¯¸ì§€ë„ document-parse ì‚¬ìš©
                    "ocr": "auto"
                }

                for attempt in range(self.max_retries):
                    try:
                        response = requests.post(
                            self.API_URL,
                            headers=self.headers,
                            files=files,
                            data=data if data else None,
                            timeout=30
                        )

                        if response.status_code == 200:
                            result = response.json()

                            # ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                            logger.info(f"ğŸ“Š OCR API ì‘ë‹µ í‚¤: {list(result.keys())}")

                            # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê³µì‹ ë¬¸ì„œ ì‘ë‹µ êµ¬ì¡° ì‚¬ìš©)
                            extracted_text = self._extract_text_from_response(result)

                            if extracted_text:
                                logger.info(f"âœ… OCR ì„±ê³µ: {len(extracted_text)}ì ì¶”ì¶œ")

                                # RAGìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ HTML ë‘˜ ë‹¤ ë°˜í™˜
                                return {
                                    "text": extracted_text,  # ê²€ìƒ‰ìš© ìˆœìˆ˜ í…ìŠ¤íŠ¸
                                    "html": result.get("content", {}).get("html", ""),  # êµ¬ì¡° ë³´ì¡´ìš© HTML
                                    "full_html": result.get("content", {}).get("html", ""),  # ì›ë³¸ HTML (ë³„ì¹­)
                                    "elements": result.get("elements", []),
                                    "source_url": url
                                }
                            else:
                                logger.warning("âš ï¸  OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                                logger.warning(f"ì‘ë‹µ ì „ì²´ êµ¬ì¡°: {result}")
                                return None
                        else:
                            logger.warning(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                    except Exception as e:
                        if attempt < self.max_retries - 1:
                            wait_time = 2 ** attempt
                            logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                            time.sleep(wait_time)
                        else:
                            logger.error(f"OCR ì‹¤íŒ¨: {e}")
                            raise

            except Exception as download_error:
                logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {download_error}")
                return None

            return None

        except Exception as e:
            # Data URIëŠ” ì§§ê²Œ ë¡œê¹…
            if url.startswith('data:'):
                log_url = "Data URI (Base64 ì´ë¯¸ì§€)"
            else:
                log_url = url[:100] + "..." if len(url) > 100 else url
            logger.error(f"ì´ë¯¸ì§€ OCR ì¤‘ ì˜¤ë¥˜: {log_url} - {e}")
            return None

    def _extract_text_from_response(self, result: Dict) -> str:
        """
        Upstage Document Parse API ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        ê³µì‹ ë¬¸ì„œ ì‘ë‹µ êµ¬ì¡°:
        {
            "content": {
                "html": "<h1>...</h1>",
                "markdown": "...",
                "text": "..."
            },
            "elements": [
                {
                    "category": "heading1",
                    "content": {
                        "html": "<h1>...</h1>",
                        "text": "..."
                    }
                }
            ]
        }
        """
        try:
            # 1. content.text ìš°ì„  (ì „ì²´ í…ìŠ¤íŠ¸)
            if "content" in result:
                content = result["content"]
                if isinstance(content, dict):
                    text = content.get("text", "")
                    if text:
                        return text

            # 2. elementsì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if "elements" in result:
                texts = []
                for element in result.get("elements", []):
                    if isinstance(element, dict) and "content" in element:
                        elem_content = element["content"]
                        if isinstance(elem_content, dict):
                            elem_text = elem_content.get("text", "")
                            if elem_text:
                                texts.append(elem_text)

                if texts:
                    return "\n\n".join(texts)

            # 3. HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (text í•„ë“œê°€ ë¹„ì–´ìˆì„ ë•Œ)
            # content.textì™€ elements[].content.textê°€ ë¹„ì–´ìˆì–´ë„ HTMLì— í…ìŠ¤íŠ¸ê°€ ìˆì„ ìˆ˜ ìˆìŒ
            html_texts = []

            # 3-1. content.htmlì—ì„œ ì¶”ì¶œ
            if "content" in result:
                content = result["content"]
                if isinstance(content, dict):
                    html = content.get("html", "")
                    if html:
                        html_text = self._extract_text_from_html(html)
                        if html_text:
                            html_texts.append(html_text)

            # 3-2. elements[].content.htmlì—ì„œ ì¶”ì¶œ
            if "elements" in result and not html_texts:
                for element in result.get("elements", []):
                    if isinstance(element, dict) and "content" in element:
                        elem_content = element["content"]
                        if isinstance(elem_content, dict):
                            elem_html = elem_content.get("html", "")
                            if elem_html:
                                elem_text = self._extract_text_from_html(elem_html)
                                if elem_text:
                                    html_texts.append(elem_text)

            if html_texts:
                return "\n\n".join(html_texts)

            # 4. Fallback: ìµœìƒìœ„ text í•„ë“œ
            if "text" in result:
                return result["text"]

            logger.warning("ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return ""

        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""

    def _extract_text_from_html(self, html: str) -> str:
        """
        HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (BeautifulSoup ì‚¬ìš©)

        Upstage APIê°€ text í•„ë“œë¥¼ ë¹„ì›Œë‘ê³  HTMLë§Œ ì œê³µí•˜ëŠ” ê²½ìš°ê°€ ìˆìŒ
        íŠ¹íˆ ì´ë¯¸ì§€ OCR ê²°ê³¼ì˜ ê²½ìš° <img alt="..."> ì†ì„±ì— í…ìŠ¤íŠ¸ê°€ ë“¤ì–´ìˆìŒ

        Args:
            html: HTML ë¬¸ìì—´

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        try:
            from bs4 import BeautifulSoup

            soup = BeautifulSoup(html, 'html.parser')

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì „ëµ:
            # 1. img[alt] ì†ì„± ìš°ì„  (OCR ê²°ê³¼)
            # 2. ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ (êµ¬ì¡° ìœ ì§€)

            texts = []

            # 1. img íƒœê·¸ì˜ alt ì†ì„±ì—ì„œ ì¶”ì¶œ (OCR ê²°ê³¼ê°€ ì—¬ê¸° ë“¤ì–´ìˆì„ ìˆ˜ ìˆìŒ)
            for img in soup.find_all('img'):
                alt_text = img.get('alt', '').strip()
                if alt_text and alt_text != 'x':  # 'x'ëŠ” ì˜ë¯¸ì—†ëŠ” í”Œë ˆì´ìŠ¤í™€ë”
                    texts.append(alt_text)

            # 2. h1, h2, p, li ë“± êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìˆœì„œ ìœ ì§€)
            for elem in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'li', 'td', 'th']):
                elem_text = elem.get_text(strip=True)
                if elem_text:
                    # ì¤‘ë³µ ë°©ì§€: altì—ì„œ ì´ë¯¸ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
                    if not any(elem_text in existing for existing in texts):
                        texts.append(elem_text)

            # 3. ìœ„ì—ì„œ ì¶”ì¶œ ëª»í–ˆìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if not texts:
                body_text = soup.get_text(separator='\n', strip=True)
                if body_text:
                    texts.append(body_text)

            return '\n\n'.join(texts)

        except Exception as e:
            logger.warning(f"HTML í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""

    def is_document_url(self, url: str) -> bool:
        """URLì´ ì§€ì›ë˜ëŠ” ë¬¸ì„œ íƒ€ì…ì¸ì§€ í™•ì¸"""
        file_ext = Path(url).suffix.lower()
        return file_ext in self.SUPPORTED_DOCUMENT_TYPES

    def is_image_url(self, url: str) -> bool:
        """URLì´ ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ íƒ€ì…ì¸ì§€ í™•ì¸"""
        file_ext = Path(url).suffix.lower()
        return file_ext in self.SUPPORTED_IMAGE_TYPES
