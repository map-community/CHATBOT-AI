"""
Upstage API í´ë¼ì´ì–¸íŠ¸
Document Parse, OCR ë“± Upstage ì„œë¹„ìŠ¤ í†µí•©
"""
import os
import requests
import logging
from typing import Optional, Dict, List
from pathlib import Path
import time
import zipfile
import io

logger = logging.getLogger(__name__)


class UpstageClient:
    """
    Upstage API í†µí•© í´ë¼ì´ì–¸íŠ¸

    ì§€ì› ê¸°ëŠ¥:
    - Document Parse: PDF, DOCX, HWP, PPTX ë“±
    - OCR: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - Vision: ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± (í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)
    """

    # Upstage Document Digitization API (í†µí•© ì—”ë“œí¬ì¸íŠ¸)
    # Document Parseì™€ OCR ëª¨ë‘ ì´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©, model íŒŒë¼ë¯¸í„°ë¡œ êµ¬ë¶„
    API_URL = "https://api.upstage.ai/v1/document-digitization"

    # ì§€ì› íŒŒì¼ íƒ€ì… (Upstage ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
    # Supported file formats: JPEG, PNG, BMP, PDF, TIFF, HEIC, DOCX, PPTX, XLSX, HWP, HWPX
    SUPPORTED_DOCUMENT_TYPES = {
        '.pdf', '.docx', '.doc', '.pptx', '.ppt',
        '.hwp', '.hwpx',  # âœ… HWPX ì¶”ê°€ (í•œì»´ì˜¤í”¼ìŠ¤ 2014+)
        '.xlsx', '.xls'
    }

    SUPPORTED_IMAGE_TYPES = {
        '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp',
        '.tiff', '.tif',  # âœ… TIFF ì¶”ê°€
        '.heic'  # âœ… HEIC ì¶”ê°€ (Apple ì´ë¯¸ì§€ í¬ë§·)
    }

    def __init__(self, api_key: Optional[str] = None, max_retries: int = 3):
        """
        Args:
            api_key: Upstage API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            max_retries: API ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
        """
        self.api_key = api_key or os.getenv('UPSTAGE_API_KEY')
        if not self.api_key:
            raise ValueError("UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.max_retries = max_retries
        self.headers = {
            "Authorization": f"Bearer {self.api_key}"
        }

    def parse_document_from_url(self, url: str) -> Optional[Dict]:
        """
        URLì—ì„œ ë¬¸ì„œë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  Document Parse APIë¡œ ì²˜ë¦¬

        Args:
            url: ë¬¸ì„œ URL

        Returns:
            {
                "text": "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                "html": "HTML í˜•ì‹",
                "elements": [...],  # êµ¬ì¡°í™”ëœ ìš”ì†Œë“¤
                "source_url": "..."
            }
            ì‹¤íŒ¨ ì‹œ None
        """
        try:
            logger.info(f"ğŸ“„ Document Parse ì‹œì‘: {url}")

            # URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ í›„ ì—…ë¡œë“œ
            try:
                # download.phpì˜ ê²½ìš° ì„¸ì…˜ ìœ ì§€ê°€ í•„ìš” (ë´‡ ì°¨ë‹¨ ìš°íšŒ)
                if 'download.php' in url:
                    from urllib.parse import urlparse, parse_qs

                    # URL íŒŒì‹±
                    parsed = urlparse(url)
                    params = parse_qs(parsed.query)

                    # ì„¸ì…˜ ìƒì„±
                    session = requests.Session()
                    session.headers.update({
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })

                    # ë² ì´ìŠ¤ URL
                    base_url = f"{parsed.scheme}://{parsed.netloc}"

                    # 1ë‹¨ê³„: ê²Œì‹œíŒ ë°©ë¬¸ (bo_tableë§Œ)
                    if 'bo_table' in params:
                        bo_table = params['bo_table'][0]
                        board_url = f"{base_url}/bbs/board.php?bo_table={bo_table}"
                        logger.info(f"ğŸ”— 1ë‹¨ê³„: ê²Œì‹œíŒ ë°©ë¬¸ - {board_url}")
                        session.get(board_url, timeout=30)

                    # 2ë‹¨ê³„: ê¸€ ë°©ë¬¸ (bo_table + wr_id)
                    if 'bo_table' in params and 'wr_id' in params:
                        bo_table = params['bo_table'][0]
                        wr_id = params['wr_id'][0]
                        post_url = f"{base_url}/bbs/board.php?bo_table={bo_table}&wr_id={wr_id}"
                        logger.info(f"ğŸ”— 2ë‹¨ê³„: ê¸€ ë°©ë¬¸ - {post_url}")
                        session.get(post_url, timeout=30)

                    # 3ë‹¨ê³„: ë‹¤ìš´ë¡œë“œ (ì„¸ì…˜ ìœ ì§€ ìƒíƒœ)
                    logger.info(f"ğŸ”— 3ë‹¨ê³„: íŒŒì¼ ë‹¤ìš´ë¡œë“œ - {url}")
                    file_response = session.get(url, timeout=30, allow_redirects=True)
                else:
                    # ì¼ë°˜ URLì€ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
                    file_response = requests.get(url, timeout=30, allow_redirects=True)

                if file_response.status_code != 200:
                    logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}")
                    return None

                # Content-Typeê³¼ Content-Dispositionì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                content_type = file_response.headers.get('Content-Type', '').lower()
                content_disposition = file_response.headers.get('Content-Disposition', '')

                logger.info(f"ğŸ“Š ì‘ë‹µ ì •ë³´: Content-Type={content_type}, Content-Disposition={content_disposition}")

                # ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: Content-Disposition > URL ê²½ë¡œ)
                filename = None

                # 1. Content-Disposition í—¤ë”ì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ (ê°€ì¥ ì‹ ë¢°ì„± ë†’ìŒ)
                if 'filename=' in content_disposition:
                    import re
                    # RFC 5987: filename*=UTF-8''encoded_filename ë˜ëŠ” filename="regular_filename"
                    match = re.search(r"filename\*=(?:UTF-8'')?([^;]+)|filename=([^;]+)", content_disposition)
                    if match:
                        encoded_filename = match.group(1)
                        regular_filename = match.group(2)

                        if encoded_filename:
                            # URL ë””ì½”ë”©
                            from urllib.parse import unquote
                            filename = unquote(encoded_filename).strip('"\'')
                        elif regular_filename:
                            filename = regular_filename.strip('"\'')

                # 2. URL ê²½ë¡œì—ì„œ ì¶”ì¶œ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ)
                if not filename:
                    from urllib.parse import urlparse, parse_qs, unquote

                    parsed_url = urlparse(url)
                    query_params = parse_qs(parsed_url.query)

                    # download.php?..., view_image.php?fn=... ê°™ì€ í”„ë¡ì‹œ URL ì²˜ë¦¬
                    # ìš°ì„ ìˆœìœ„: fn > file > ê²½ë¡œ
                    actual_filename = None

                    if 'fn' in query_params:
                        # fn íŒŒë¼ë¯¸í„°ì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ (view_image.php)
                        fn_value = query_params['fn'][0]
                        decoded_fn = unquote(fn_value)
                        actual_filename = Path(decoded_fn).name
                        logger.info(f"ğŸ” í”„ë¡ì‹œ URL ê°ì§€ (fn) - ì‹¤ì œ íŒŒì¼ëª…: {actual_filename}")
                    elif 'file' in query_params:
                        # file íŒŒë¼ë¯¸í„°ì—ì„œ ì¶”ì¶œ (ì¼ë¶€ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸)
                        file_value = query_params['file'][0]
                        decoded_file = unquote(file_value)
                        actual_filename = Path(decoded_file).name
                        logger.info(f"ğŸ” í”„ë¡ì‹œ URL ê°ì§€ (file) - ì‹¤ì œ íŒŒì¼ëª…: {actual_filename}")

                    if actual_filename:
                        filename = actual_filename
                    else:
                        # ì¼ë°˜ URL: ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                        filename = Path(parsed_url.path).name
                        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°
                        if '?' in filename:
                            filename = filename.split('?')[0]

                # 3. Content-Typeì—ì„œ í™•ì¥ì ìœ ì¶” (ìµœí›„ì˜ ìˆ˜ë‹¨)
                if not filename or filename == 'download.php' or not Path(filename).suffix:
                    type_to_ext = {
                        'application/pdf': '.pdf',
                        'application/msword': '.doc',
                        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
                        'application/x-hwp': '.hwp',
                        'application/haansofthwp': '.hwp',
                        'application/vnd.hancom.hwp': '.hwp',
                        'application/vnd.hancom.hwpx': '.hwpx',  # âœ… HWPX ì¶”ê°€
                        'application/vnd.ms-powerpoint': '.ppt',
                        'application/vnd.openxmlformats-officedocument.presentationml.presentation': '.pptx',
                        'application/vnd.ms-excel': '.xls',
                        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx'
                    }
                    for mime_type, ext in type_to_ext.items():
                        if mime_type in content_type:
                            filename = f"document{ext}"
                            break

                logger.info(f"ğŸ“„ ìµœì¢… íŒŒì¼ëª…: {filename}")

                # íŒŒì¼ í™•ì¥ì í™•ì¸
                file_ext = Path(filename).suffix.lower()

                # ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸
                supported_image_types = [
                    'image/jpeg', 'image/jpg', 'image/png', 'image/gif',
                    'image/bmp', 'image/webp',
                    'image/tiff', 'image/tif',  # âœ… TIFF ì¶”ê°€
                    'image/heic', 'image/heif'  # âœ… HEIC ì¶”ê°€
                ]
                is_image = (
                    any(t in content_type for t in supported_image_types) or
                    file_ext in self.SUPPORTED_IMAGE_TYPES
                )

                # ì´ë¯¸ì§€ íŒŒì¼ì´ë©´ OCRë¡œ ìë™ ì „í™˜
                if is_image:
                    logger.info(f"ğŸ“Š ì´ë¯¸ì§€ íŒŒì¼ ê°ì§€ ({file_ext}) - OCRë¡œ ì „í™˜")

                    # OCR API í˜¸ì¶œ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ ì‚¬ìš©)
                    files = {
                        "document": (filename, file_response.content)
                    }
                    data_param = {
                        "model": "document-parse",
                        "ocr": "auto"
                    }

                    for attempt in range(self.max_retries):
                        try:
                            response = requests.post(
                                self.API_URL,
                                headers=self.headers,
                                files=files,
                                data=data_param,
                                timeout=30
                            )

                            if response.status_code == 200:
                                result = response.json()
                                logger.info(f"ğŸ“Š OCR API ì‘ë‹µ í‚¤: {list(result.keys())}")

                                extracted_text = self._extract_text_from_response(result)

                                if extracted_text:
                                    logger.info(f"âœ… OCR ì„±ê³µ (ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼): {len(extracted_text)}ì ì¶”ì¶œ")
                                    return {
                                        "text": extracted_text,
                                        "html": result.get("content", {}).get("html", ""),
                                        "full_html": result.get("content", {}).get("html", ""),
                                        "elements": result.get("elements", []),
                                        "source_url": url
                                    }
                                else:
                                    logger.warning("âš ï¸  OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ (ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼)")
                                    return None
                            else:
                                logger.warning(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                        except Exception as e:
                            if attempt < self.max_retries - 1:
                                wait_time = 2 ** attempt
                                logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                                time.sleep(wait_time)
                            else:
                                logger.error(f"OCR ì‹¤íŒ¨ (ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼): {e}")
                                raise

                    return None

                # Content-Typeìœ¼ë¡œ ë¬¸ì„œ íƒ€ì… í™•ì¸
                supported_types = [
                    'application/pdf',
                    'application/msword',
                    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    'application/vnd.ms-powerpoint',
                    'application/vnd.openxmlformats-officedocument.presentationml.presentation',
                    'application/vnd.ms-excel',
                    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    'application/x-hwp',  # HWP
                    'application/haansofthwp',  # HWP
                ]

                # ë¬¸ì„œ íƒ€ì… í™•ì¸
                is_supported = (
                    any(t in content_type for t in supported_types) or
                    file_ext in self.SUPPORTED_DOCUMENT_TYPES
                )

                if not is_supported:
                    logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {content_type}, í™•ì¥ì: {file_ext}")
                    logger.warning(f"URL: {url}")
                    logger.warning(f"íŒŒì¼ëª…: {filename}")
                    return None

                # íŒŒì¼ëª…ì´ ê¸¸ë©´ ì¤„ì„
                display_name = filename if len(filename) <= 30 else f"{filename[:27]}..."
                logger.info(f"ğŸ“„ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {display_name}")

                # Upstage Document Parse API í˜¸ì¶œ (íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹)
                # âœ… 100í˜ì´ì§€ ì œí•œ: Synchronous APIëŠ” ìë™ìœ¼ë¡œ ì²« 100í˜ì´ì§€ë§Œ ì²˜ë¦¬
                # (ê³µì‹ ë¬¸ì„œ: For files exceeding 100 pages, the first 100 pages are processed)
                files = {
                    "document": (filename, file_response.content)
                }
                data = {
                    "model": "document-parse",  # í•„ìˆ˜!
                    "ocr": "auto"  # OCR ìë™ í™œì„±í™” (PDF ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ , í•„ìš”ì‹œ OCR)
                }

                for attempt in range(self.max_retries):
                    try:
                        response = requests.post(
                            self.API_URL,
                            headers=self.headers,
                            files=files,
                            data=data,
                            timeout=60
                        )

                        if response.status_code == 200:
                            result = response.json()

                            # ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                            logger.info(f"ğŸ“Š Document Parse API ì‘ë‹µ í‚¤: {list(result.keys())}")

                            # í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê³µì‹ ë¬¸ì„œ ì‘ë‹µ êµ¬ì¡° ì‚¬ìš©)
                            extracted_text = self._extract_text_from_response(result)

                            if extracted_text:
                                logger.info(f"âœ… Document Parse ì„±ê³µ: {len(extracted_text)}ì ì¶”ì¶œ")
                            else:
                                logger.warning(f"âš ï¸  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨. ì‘ë‹µ êµ¬ì¡°: {result}")

                            # RAGìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ HTML ë‘˜ ë‹¤ ë°˜í™˜
                            return {
                                "text": extracted_text,  # ê²€ìƒ‰ìš© ìˆœìˆ˜ í…ìŠ¤íŠ¸
                                "html": result.get("content", {}).get("html", ""),  # êµ¬ì¡° ë³´ì¡´ìš© HTML
                                "full_html": result.get("content", {}).get("html", ""),  # ì›ë³¸ HTML (ë³„ì¹­)
                                "markdown": result.get("content", {}).get("markdown", ""),  # Markdown (ìˆìœ¼ë©´)
                                "elements": result.get("elements", []),
                                "source_url": url
                            }
                        else:
                            logger.warning(f"Document Parse API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                    except Exception as e:
                        if attempt < self.max_retries - 1:
                            wait_time = 2 ** attempt
                            logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                            time.sleep(wait_time)
                        else:
                            logger.error(f"Document Parse ì‹¤íŒ¨: {e}")
                            raise

            except Exception as download_error:
                logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {download_error}")
                return None

            return None

        except Exception as e:
            logger.error(f"ë¬¸ì„œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {url} - {e}")
            return None

    def extract_text_from_image_url(self, url: str) -> Optional[Dict]:
        """
        ì´ë¯¸ì§€ URLì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            url: ì´ë¯¸ì§€ URL

        Returns:
            {
                "text": "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                "confidence": 0.95,
                "words": [...]
            }
            ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # Data URIëŠ” ì§§ê²Œ ë¡œê¹…
            if url.startswith('data:'):
                log_url = "Data URI (Base64 ì´ë¯¸ì§€)"
            else:
                log_url = url[:100] + "..." if len(url) > 100 else url
            logger.info(f"ğŸ–¼ï¸  OCR ì‹œì‘: {log_url}")

            # Data URI Scheme ì²˜ë¦¬ (data:image/png;base64,...)
            if url.startswith('data:'):
                try:
                    import base64
                    import re

                    logger.info("ğŸ“Š Data URI ê°ì§€ - Base64 ë””ì½”ë”© ì‹œì‘")

                    # Data URI íŒŒì‹±: data:[<mediatype>][;base64],<data>
                    match = re.match(r'data:([^;]+);base64,(.+)', url)
                    if not match:
                        logger.error("Data URI í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ (base64 ì¸ì½”ë”© í•„ìš”)")
                        return None

                    mime_type = match.group(1)  # image/png, image/jpeg ë“±
                    base64_data = match.group(2)

                    # MIME íƒ€ì… í™•ì¸
                    supported_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/bmp', 'image/webp']
                    if mime_type not in supported_types:
                        logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {mime_type}")
                        return None

                    # Base64 ë””ì½”ë”©
                    image_data = base64.b64decode(base64_data)
                    data_length = len(image_data)

                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    if data_length < 100:
                        logger.warning(f"ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë„ˆë¬´ ì‘ìŒ ({data_length} bytes)")
                        return None

                    # í™•ì¥ì ê²°ì •
                    ext_map = {
                        'image/jpeg': '.jpg',
                        'image/jpg': '.jpg',
                        'image/png': '.png',
                        'image/gif': '.gif',
                        'image/bmp': '.bmp',
                        'image/webp': '.webp'
                    }
                    extension = ext_map.get(mime_type, '.jpg')
                    filename = f"data_uri_image{extension}"

                    logger.info(f"ğŸ“Š ë””ì½”ë”© ì„±ê³µ: {mime_type}, {data_length} bytes")

                    # Upstage OCR API í˜¸ì¶œ
                    files = {
                        "document": (filename, image_data)
                    }
                    data_param = {
                        "model": "document-parse",
                        "ocr": "auto"
                    }

                    for attempt in range(self.max_retries):
                        try:
                            response = requests.post(
                                self.API_URL,
                                headers=self.headers,
                                files=files,
                                data=data_param,
                                timeout=30
                            )

                            if response.status_code == 200:
                                result = response.json()

                                # ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                                logger.info(f"ğŸ“Š OCR API ì‘ë‹µ í‚¤: {list(result.keys())}")

                                # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                extracted_text = self._extract_text_from_response(result)

                                if extracted_text:
                                    logger.info(f"âœ… OCR ì„±ê³µ (Data URI): {len(extracted_text)}ì ì¶”ì¶œ")

                                    # RAGìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ HTML ë‘˜ ë‹¤ ë°˜í™˜
                                    return {
                                        "text": extracted_text,
                                        "html": result.get("content", {}).get("html", ""),
                                        "full_html": result.get("content", {}).get("html", ""),
                                        "elements": result.get("elements", []),
                                        "source_url": "data_uri"  # Data URIëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ "data_uri"ë¡œ í‘œì‹œ
                                    }
                                else:
                                    logger.warning("âš ï¸  OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ (Data URI)")
                                    return None
                            else:
                                logger.warning(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                        except Exception as e:
                            if attempt < self.max_retries - 1:
                                wait_time = 2 ** attempt
                                logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                                time.sleep(wait_time)
                            else:
                                logger.error(f"OCR ì‹¤íŒ¨ (Data URI): {e}")
                                raise

                    return None

                except Exception as data_uri_error:
                    logger.error(f"Data URI ì²˜ë¦¬ ì˜¤ë¥˜: {data_uri_error}")
                    return None

            # ì¼ë°˜ HTTP/HTTPS URL ì²˜ë¦¬
            # view_image.php ê°™ì€ í”„ë¡ì‹œ URLì„ ì‹¤ì œ ì´ë¯¸ì§€ URLë¡œ ë³€í™˜
            actual_url = url
            from urllib.parse import urlparse, parse_qs, unquote

            parsed = urlparse(url)

            # view_image.php?fn=... ì²˜ë¦¬
            if 'view_image.php' in parsed.path and 'fn' in parse_qs(parsed.query):
                fn_value = parse_qs(parsed.query)['fn'][0]
                decoded_path = unquote(fn_value)  # /data/editor/2511/...png

                # ì ˆëŒ€ URLë¡œ ë³€í™˜
                base_url = f"{parsed.scheme}://{parsed.netloc}"
                actual_url = f"{base_url}{decoded_path}"
                logger.info(f"ğŸ” í”„ë¡ì‹œ URL ë³€í™˜: view_image.php â†’ {decoded_path}")

            # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë¦¬ë‹¤ì´ë ‰íŠ¸ ë”°ë¼ê°€ê¸°!)
            try:
                file_response = requests.get(actual_url, timeout=30, allow_redirects=True)
                if file_response.status_code != 200:
                    log_url = url[:100] + "..." if len(url) > 100 else url
                    logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {log_url}")
                    return None

                # Content-Type í™•ì¸
                content_type = file_response.headers.get('Content-Type', '').lower()
                content_disposition = file_response.headers.get('Content-Disposition', '')

                # ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: Content-Disposition > URL ê²½ë¡œ)
                filename = None

                # 1. Content-Disposition í—¤ë”
                if 'filename=' in content_disposition:
                    import re
                    match = re.search(r"filename\*=(?:UTF-8'')?([^;]+)|filename=([^;]+)", content_disposition)
                    if match:
                        encoded_filename = match.group(1)
                        regular_filename = match.group(2)

                        if encoded_filename:
                            from urllib.parse import unquote
                            filename = unquote(encoded_filename).strip('"\'')
                        elif regular_filename:
                            filename = regular_filename.strip('"\'')

                # 2. URL ê²½ë¡œ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ)
                if not filename:
                    from urllib.parse import urlparse, parse_qs, unquote

                    parsed_url = urlparse(url)
                    query_params = parse_qs(parsed_url.query)

                    # view_image.php?fn=... ê°™ì€ í”„ë¡ì‹œ URL ì²˜ë¦¬
                    if 'fn' in query_params:
                        # fn íŒŒë¼ë¯¸í„°ì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ
                        fn_value = query_params['fn'][0]
                        # URL ë””ì½”ë”© (%2F â†’ /)
                        decoded_fn = unquote(fn_value)
                        # ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
                        filename = Path(decoded_fn).name
                        logger.info(f"ğŸ” í”„ë¡ì‹œ URL ê°ì§€ - ì‹¤ì œ íŒŒì¼ëª…: {filename}")
                    else:
                        # ì¼ë°˜ URL: ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                        filename = Path(parsed_url.path).name
                        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°
                        if '?' in filename:
                            filename = filename.split('?')[0]

                # ì´ë¯¸ì§€ íƒ€ì… í™•ì¸
                supported_image_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/bmp', 'image/webp']
                file_ext = Path(filename).suffix.lower()

                is_image = (
                    any(t in content_type for t in supported_image_types) or
                    file_ext in self.SUPPORTED_IMAGE_TYPES
                )

                if not is_image:
                    log_url = url[:100] + "..." if len(url) > 100 else url
                    logger.warning(f"ì´ë¯¸ì§€ê°€ ì•„ë‹˜: {content_type}, í™•ì¥ì: {file_ext}, URL: {log_url}")
                    return None

                # íŒŒì¼ í¬ê¸° í™•ì¸ (ë„ˆë¬´ ì‘ìœ¼ë©´ ì†ìƒë˜ì—ˆì„ ê°€ëŠ¥ì„±)
                content_length = len(file_response.content)
                if content_length < 100:
                    log_url = url[:100] + "..." if len(url) > 100 else url
                    logger.warning(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ ({content_length} bytes): {log_url}")
                    return None

                # íŒŒì¼ëª…ì´ ê¸¸ë©´ ì¤„ì„
                display_name = filename if len(filename) <= 30 else f"{filename[:27]}..."
                logger.info(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {display_name}, {content_length} bytes")

                # Upstage OCR API í˜¸ì¶œ (íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹)
                # ì´ë¯¸ì§€ë„ document-parse ëª¨ë¸ë¡œ ì²˜ë¦¬ (ìë™ OCR)
                files = {
                    "document": (filename, file_response.content)
                }
                data = {
                    "model": "document-parse",  # í•„ìˆ˜! ì´ë¯¸ì§€ë„ document-parse ì‚¬ìš©
                    "ocr": "auto"
                }

                for attempt in range(self.max_retries):
                    try:
                        response = requests.post(
                            self.API_URL,
                            headers=self.headers,
                            files=files,
                            data=data if data else None,
                            timeout=30
                        )

                        if response.status_code == 200:
                            result = response.json()

                            # ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                            logger.info(f"ğŸ“Š OCR API ì‘ë‹µ í‚¤: {list(result.keys())}")

                            # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê³µì‹ ë¬¸ì„œ ì‘ë‹µ êµ¬ì¡° ì‚¬ìš©)
                            extracted_text = self._extract_text_from_response(result)

                            if extracted_text:
                                logger.info(f"âœ… OCR ì„±ê³µ: {len(extracted_text)}ì ì¶”ì¶œ")

                                # RAGìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ HTML ë‘˜ ë‹¤ ë°˜í™˜
                                return {
                                    "text": extracted_text,  # ê²€ìƒ‰ìš© ìˆœìˆ˜ í…ìŠ¤íŠ¸
                                    "html": result.get("content", {}).get("html", ""),  # êµ¬ì¡° ë³´ì¡´ìš© HTML
                                    "full_html": result.get("content", {}).get("html", ""),  # ì›ë³¸ HTML (ë³„ì¹­)
                                    "elements": result.get("elements", []),
                                    "source_url": url
                                }
                            else:
                                logger.warning("âš ï¸  OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                                logger.warning(f"ì‘ë‹µ ì „ì²´ êµ¬ì¡°: {result}")
                                return None
                        else:
                            logger.warning(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}")

                    except Exception as e:
                        if attempt < self.max_retries - 1:
                            wait_time = 2 ** attempt
                            logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{self.max_retries} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                            time.sleep(wait_time)
                        else:
                            logger.error(f"OCR ì‹¤íŒ¨: {e}")
                            raise

            except Exception as download_error:
                logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {download_error}")
                return None

            return None

        except Exception as e:
            # Data URIëŠ” ì§§ê²Œ ë¡œê¹…
            if url.startswith('data:'):
                log_url = "Data URI (Base64 ì´ë¯¸ì§€)"
            else:
                log_url = url[:100] + "..." if len(url) > 100 else url
            logger.error(f"ì´ë¯¸ì§€ OCR ì¤‘ ì˜¤ë¥˜: {log_url} - {e}")
            return None

    def _extract_text_from_response(self, result: Dict) -> str:
        """
        Upstage Document Parse API ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        ê³µì‹ ë¬¸ì„œ ì‘ë‹µ êµ¬ì¡°:
        {
            "content": {
                "html": "<h1>...</h1>",
                "markdown": "...",  # í‘œ êµ¬ì¡° ë³´ì¡´!
                "text": "..."
            },
            "elements": [
                {
                    "category": "heading1",
                    "content": {
                        "html": "<h1>...</h1>",
                        "markdown": "...",
                        "text": "..."
                    }
                }
            ]
        }
        """
        try:
            # 1. content.markdown ìš°ì„  (í‘œ êµ¬ì¡° ë³´ì¡´!)
            if "content" in result:
                content = result["content"]
                if isinstance(content, dict):
                    markdown = content.get("markdown", "")
                    if markdown:
                        logger.info(f"âœ… Markdown ì‚¬ìš© (í‘œ êµ¬ì¡° ë³´ì¡´): {len(markdown)}ì")
                        return markdown

            # 2. content.text (markdown ì—†ìœ¼ë©´)
            if "content" in result:
                content = result["content"]
                if isinstance(content, dict):
                    text = content.get("text", "")
                    if text:
                        return text

            # 3. elementsì—ì„œ markdown ìš°ì„  ì¶”ì¶œ (í‘œ êµ¬ì¡° ë³´ì¡´!)
            if "elements" in result:
                texts = []
                for element in result.get("elements", []):
                    if isinstance(element, dict) and "content" in element:
                        elem_content = element["content"]
                        if isinstance(elem_content, dict):
                            # markdown ìš°ì„ 
                            elem_markdown = elem_content.get("markdown", "")
                            if elem_markdown:
                                texts.append(elem_markdown)
                            else:
                                # markdown ì—†ìœ¼ë©´ text ì‚¬ìš©
                                elem_text = elem_content.get("text", "")
                                if elem_text:
                                    texts.append(elem_text)

                if texts:
                    logger.info(f"âœ… Elementsì—ì„œ ì¶”ì¶œ (í‘œ êµ¬ì¡° ë³´ì¡´ ê°€ëŠ¥): {len(texts)}ê°œ ìš”ì†Œ")
                    return "\n\n".join(texts)

            # 4. HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (markdown/text í•„ë“œê°€ ë¹„ì–´ìˆì„ ë•Œ)
            # Fallback: content.markdown, content.text, elementsê°€ ëª¨ë‘ ë¹„ì–´ìˆì„ ë•Œë§Œ ì‚¬ìš©
            html_texts = []

            # 4-1. content.htmlì—ì„œ ì¶”ì¶œ
            if "content" in result:
                content = result["content"]
                if isinstance(content, dict):
                    html = content.get("html", "")
                    if html:
                        html_text = self._extract_text_from_html(html)
                        if html_text:
                            html_texts.append(html_text)

            # 4-2. elements[].content.htmlì—ì„œ ì¶”ì¶œ
            if "elements" in result and not html_texts:
                for element in result.get("elements", []):
                    if isinstance(element, dict) and "content" in element:
                        elem_content = element["content"]
                        if isinstance(elem_content, dict):
                            elem_html = elem_content.get("html", "")
                            if elem_html:
                                elem_text = self._extract_text_from_html(elem_html)
                                if elem_text:
                                    html_texts.append(elem_text)

            if html_texts:
                return "\n\n".join(html_texts)

            # 5. Fallback: ìµœìƒìœ„ text í•„ë“œ
            if "text" in result:
                return result["text"]

            logger.warning("ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return ""

        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""

    def _extract_text_from_html(self, html: str) -> str:
        """
        HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (BeautifulSoup ì‚¬ìš©)

        Upstage APIê°€ text í•„ë“œë¥¼ ë¹„ì›Œë‘ê³  HTMLë§Œ ì œê³µí•˜ëŠ” ê²½ìš°ê°€ ìˆìŒ
        íŠ¹íˆ ì´ë¯¸ì§€ OCR ê²°ê³¼ì˜ ê²½ìš° <img alt="..."> ì†ì„±ì— í…ìŠ¤íŠ¸ê°€ ë“¤ì–´ìˆìŒ

        Args:
            html: HTML ë¬¸ìì—´

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        try:
            from bs4 import BeautifulSoup

            soup = BeautifulSoup(html, 'html.parser')

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì „ëµ:
            # 1. img[alt] ì†ì„± ìš°ì„  (OCR ê²°ê³¼)
            # 2. ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ (êµ¬ì¡° ìœ ì§€)

            texts = []

            # 1. img íƒœê·¸ì˜ alt ì†ì„±ì—ì„œ ì¶”ì¶œ (OCR ê²°ê³¼ê°€ ì—¬ê¸° ë“¤ì–´ìˆì„ ìˆ˜ ìˆìŒ)
            for img in soup.find_all('img'):
                alt_text = img.get('alt', '').strip()
                if alt_text and alt_text != 'x':  # 'x'ëŠ” ì˜ë¯¸ì—†ëŠ” í”Œë ˆì´ìŠ¤í™€ë”
                    texts.append(alt_text)

            # 2. h1, h2, p, li ë“± êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìˆœì„œ ìœ ì§€)
            for elem in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'li', 'td', 'th']):
                elem_text = elem.get_text(strip=True)
                if elem_text:
                    # ì¤‘ë³µ ë°©ì§€: altì—ì„œ ì´ë¯¸ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
                    if not any(elem_text in existing for existing in texts):
                        texts.append(elem_text)

            # 3. ìœ„ì—ì„œ ì¶”ì¶œ ëª»í–ˆìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if not texts:
                body_text = soup.get_text(separator='\n', strip=True)
                if body_text:
                    texts.append(body_text)

            return '\n\n'.join(texts)

        except Exception as e:
            logger.warning(f"HTML í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ""

    def is_document_url(self, url: str) -> bool:
        """URLì´ ì§€ì›ë˜ëŠ” ë¬¸ì„œ íƒ€ì…ì¸ì§€ í™•ì¸"""
        file_ext = Path(url).suffix.lower()
        return file_ext in self.SUPPORTED_DOCUMENT_TYPES

    def is_image_url(self, url: str) -> bool:
        """URLì´ ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ íƒ€ì…ì¸ì§€ í™•ì¸"""
        file_ext = Path(url).suffix.lower()
        return file_ext in self.SUPPORTED_IMAGE_TYPES
    def process_zip_from_url(self, zip_url: str) -> Dict:
        """
        ZIP íŒŒì¼ ì²˜ë¦¬ (ì••ì¶• í•´ì œ í›„ ê°œë³„ íŒŒì¼ íŒŒì‹±)

        Args:
            zip_url: ZIP íŒŒì¼ URL

        Returns:
            {
                "successful": [{"filename": "...", "type": "pdf", "text": "..."}],
                "failed": [{"filename": "...", "reason": "..."}],
                "total_files": N
            }
        """
        MAX_ZIP_SIZE = 100 * 1024 * 1024  # 100MB
        MAX_TOTAL_FILES = 50  # ZIP ë‚´ ìµœëŒ€ íŒŒì¼ ìˆ˜
        MAX_EXTRACTION_SIZE = 500 * 1024 * 1024  # ì••ì¶• í•´ì œ í›„ ìµœëŒ€ í¬ê¸° (500MB, Zip Bomb ë°©ì§€)

        successful = []
        failed = []

        try:
            logger.info(f"ğŸ“¦ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {zip_url}")

            # 1. ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            response = requests.get(zip_url, timeout=30, stream=True)

            if response.status_code != 200:
                logger.error(f"ZIP ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                return {
                    "successful": [],
                    "failed": [{"filename": zip_url, "reason": f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}"}],
                    "total_files": 0
                }

            # 2. íŒŒì¼ í¬ê¸° ì²´í¬
            content_length = response.headers.get('Content-Length')
            if content_length and int(content_length) > MAX_ZIP_SIZE:
                logger.warning(f"ZIP íŒŒì¼ì´ ë„ˆë¬´ í¼: {content_length} bytes (ìµœëŒ€: {MAX_ZIP_SIZE})")
                return {
                    "successful": [],
                    "failed": [{"filename": zip_url, "reason": f"íŒŒì¼ í¬ê¸° ì´ˆê³¼: {content_length} bytes"}],
                    "total_files": 0
                }

            # 3. ë©”ëª¨ë¦¬ì— ë¡œë“œ
            zip_data = response.content
            logger.info(f"ğŸ“¦ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(zip_data)} bytes")

            # 4. ZIP ì••ì¶• í•´ì œ ë° ê°œë³„ íŒŒì¼ ì²˜ë¦¬
            with zipfile.ZipFile(io.BytesIO(zip_data)) as zf:
                file_list = zf.namelist()

                # íŒŒì¼ ê°œìˆ˜ ì²´í¬
                if len(file_list) > MAX_TOTAL_FILES:
                    logger.warning(f"ZIP ë‚´ íŒŒì¼ ê°œìˆ˜ ì´ˆê³¼: {len(file_list)} (ìµœëŒ€: {MAX_TOTAL_FILES})")
                    return {
                        "successful": [],
                        "failed": [{"filename": zip_url, "reason": f"íŒŒì¼ ê°œìˆ˜ ì´ˆê³¼: {len(file_list)}"}],
                        "total_files": len(file_list)
                    }

                logger.info(f"ğŸ“¦ ZIP ë‚´ íŒŒì¼ ê°œìˆ˜: {len(file_list)}")

                total_extraction_size = 0

                for file_info in zf.infolist():
                    # ë””ë ‰í† ë¦¬ ìŠ¤í‚µ
                    if file_info.is_dir():
                        continue

                    filename = file_info.filename
                    file_size = file_info.file_size

                    # ì••ì¶• í•´ì œ í¬ê¸° ëˆ„ì  ì²´í¬ (Zip Bomb ë°©ì§€)
                    total_extraction_size += file_size
                    if total_extraction_size > MAX_EXTRACTION_SIZE:
                        logger.warning(f"ZIP ì••ì¶• í•´ì œ í¬ê¸° ì´ˆê³¼ (Zip Bomb ì˜ì‹¬): {total_extraction_size}")
                        failed.append({
                            "filename": filename,
                            "reason": "ZIP ì••ì¶• í•´ì œ í¬ê¸° ì´ˆê³¼ (Zip Bomb ì˜ì‹¬)"
                        })
                        continue

                    try:
                        # íŒŒì¼ ë°ì´í„° ì¶”ì¶œ
                        file_data = zf.read(file_info)
                        file_ext = Path(filename).suffix.lower()

                        logger.info(f"  ğŸ“„ ì²˜ë¦¬ ì¤‘: {filename} ({file_ext}, {file_size} bytes)")

                        # ì§€ì› í˜•ì‹ í™•ì¸
                        if file_ext in self.SUPPORTED_DOCUMENT_TYPES:
                            # ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬
                            result = self._process_document_from_bytes(file_data, filename)
                            if result:
                                successful.append(result)
                                logger.info(f"  âœ… ì„±ê³µ: {filename} ({len(result['text'])}ì)")
                            else:
                                failed.append({
                                    "filename": filename,
                                    "reason": "ë¬¸ì„œ íŒŒì‹± ì‹¤íŒ¨ (í…ìŠ¤íŠ¸ ì—†ìŒ)"
                                })
                                logger.warning(f"  âŒ ì‹¤íŒ¨: {filename} (í…ìŠ¤íŠ¸ ì—†ìŒ)")

                        elif file_ext in self.SUPPORTED_IMAGE_TYPES:
                            # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
                            result = self._process_image_from_bytes(file_data, filename)
                            if result:
                                successful.append(result)
                                logger.info(f"  âœ… ì„±ê³µ: {filename} ({len(result['text'])}ì)")
                            else:
                                failed.append({
                                    "filename": filename,
                                    "reason": "ì´ë¯¸ì§€ OCR ì‹¤íŒ¨ (í…ìŠ¤íŠ¸ ì—†ìŒ)"
                                })
                                logger.warning(f"  âŒ ì‹¤íŒ¨: {filename} (í…ìŠ¤íŠ¸ ì—†ìŒ)")

                        else:
                            # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹
                            failed.append({
                                "filename": filename,
                                "reason": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {file_ext}"
                            })
                            logger.warning(f"  â­ï¸  ìŠ¤í‚µ: {filename} (ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹)")

                    except Exception as e:
                        failed.append({
                            "filename": filename,
                            "reason": str(e)
                        })
                        logger.error(f"  âŒ ì—ëŸ¬: {filename} - {e}")

            logger.info(f"ğŸ“¦ ZIP ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {len(successful)}ê°œ, ì‹¤íŒ¨ {len(failed)}ê°œ")

            return {
                "successful": successful,
                "failed": failed,
                "total_files": len(file_list)
            }

        except zipfile.BadZipFile:
            logger.error(f"ì†ìƒëœ ZIP íŒŒì¼: {zip_url}")
            return {
                "successful": [],
                "failed": [{"filename": zip_url, "reason": "ì†ìƒëœ ZIP íŒŒì¼"}],
                "total_files": 0
            }
        except Exception as e:
            logger.error(f"ZIP ì²˜ë¦¬ ì—ëŸ¬: {e}")
            return {
                "successful": [],
                "failed": [{"filename": zip_url, "reason": str(e)}],
                "total_files": 0
            }

    def _process_document_from_bytes(self, file_data: bytes, filename: str) -> Optional[Dict]:
        """ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œë¶€í„° ë¬¸ì„œ íŒŒì‹±"""
        try:
            files = {"document": (filename, file_data)}
            data = {
                "model": "document-parse",
                "ocr": "auto"
            }

            response = requests.post(
                self.API_URL,
                headers=self.headers,
                files=files,
                data=data,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                extracted_text = self._extract_text_from_response(result)

                if extracted_text:
                    return {
                        "filename": filename,
                        "type": Path(filename).suffix.lower()[1:],
                        "text": extracted_text,
                        "html": result.get("content", {}).get("html", ""),
                        "from_zip": True
                    }

            return None

        except Exception as e:
            logger.error(f"ë¬¸ì„œ íŒŒì‹± ì‹¤íŒ¨: {filename} - {e}")
            return None

    def _process_image_from_bytes(self, file_data: bytes, filename: str) -> Optional[Dict]:
        """ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œë¶€í„° ì´ë¯¸ì§€ OCR"""
        try:
            files = {"document": (filename, file_data)}
            data = {
                "model": "document-parse",
                "ocr": "auto"
            }

            response = requests.post(
                self.API_URL,
                headers=self.headers,
                files=files,
                data=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                extracted_text = self._extract_text_from_response(result)

                if extracted_text:
                    return {
                        "filename": filename,
                        "type": "image",
                        "text": extracted_text,
                        "html": result.get("content", {}).get("html", ""),
                        "from_zip": True
                    }

            return None

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ OCR ì‹¤íŒ¨: {filename} - {e}")
            return None
