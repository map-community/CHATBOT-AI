"""
ë‹¨ì¼ URL í¬ë¡¤ë§ ë””ë²„ê·¸ ë„êµ¬

íŠ¹ì • URLì˜ í¬ë¡¤ë§ ì „ ê³¼ì •ì„ ìƒì„¸í•˜ê²Œ ì¶”ì í•˜ê³  ê¸°ë¡í•©ë‹ˆë‹¤.
ê° ì²˜ë¦¬ ë‹¨ê³„ë³„ë¡œ:
- ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ ì €ì¥
- í•¨ìˆ˜ í˜¸ì¶œ íë¦„ ë¡œê¹…
- ì¤‘ê°„ ê²°ê³¼ë¬¼ íŒŒì¼ë¡œ ì €ì¥
- ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ì •ë³´ ê¸°ë¡

ì‚¬ìš©ë²•:
    python debug_single_url.py <URL> [--category <category>]

ì˜ˆì‹œ:
    python debug_single_url.py "https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&wr_id=28848&page=2" --category notice
"""

import sys
import json
import traceback
import re
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import logging

# modules ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from pymongo import MongoClient
from config import CrawlerConfig
from crawling import NoticeCrawler, JobCrawler, SeminarCrawler
from processing import DocumentProcessor
from processing.multimodal_processor import MultimodalProcessor
from processing.upstage_client import UpstageClient


class DebugTracker:
    """
    ë””ë²„ê·¸ ì¶”ì  í´ë˜ìŠ¤

    ê° ì²˜ë¦¬ ë‹¨ê³„ì˜ ì…ë ¥/ì¶œë ¥ì„ ê¸°ë¡í•˜ê³  íŒŒì¼ë¡œ ì €ì¥
    """

    def __init__(self, url: str, category: str = "notice"):
        self.url = url
        self.category = category

        # ë””ë²„ê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (timestamp ì €ì¥)
        self.timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        self.debug_dir = Path("logs/debug") / f"debug_{self.timestamp}"
        self.debug_dir.mkdir(parents=True, exist_ok=True)

        # ë¡œê±° ì„¤ì •
        self.logger = self._setup_logger()

        # ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥
        self.steps: List[Dict[str, Any]] = []
        self.current_step = 0

        self.logger.info("="*80)
        self.logger.info(f"ğŸ” ë””ë²„ê·¸ ì„¸ì…˜ ì‹œì‘")
        self.logger.info(f"URL: {url}")
        self.logger.info(f"ì¹´í…Œê³ ë¦¬: {category}")
        self.logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.debug_dir}")
        self.logger.info("="*80)

    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("debug_tracker")
        logger.setLevel(logging.DEBUG)
        logger.handlers.clear()

        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_file = self.debug_dir / "debug.log"
        file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)

        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)

        # í¬ë§·
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)

        logger.addHandler(file_handler)
        logger.addHandler(console_handler)

        return logger

    def _sanitize_filename(self, text: str, max_length: int = 50) -> str:
        """
        íŒŒì¼/í´ë”ëª…ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í…ìŠ¤íŠ¸ ì •ì œ

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            max_length: ìµœëŒ€ ê¸¸ì´

        Returns:
            ì •ì œëœ ë¬¸ìì—´
        """
        # íŒŒì¼ëª…ì— ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ë¬¸ì ì œê±°
        # Windows/Linux/Mac ê³µí†µ: / \ : * ? " < > |
        sanitized = re.sub(r'[/\\:*?"<>|]', '', text)

        # ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì¹˜í™˜
        sanitized = sanitized.replace(' ', '_')

        # ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ í•˜ë‚˜ë¡œ
        sanitized = re.sub(r'_+', '_', sanitized)

        # ì•ë’¤ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
        sanitized = sanitized.strip('_')

        # ê¸¸ì´ ì œí•œ
        if len(sanitized) > max_length:
            sanitized = sanitized[:max_length]

        return sanitized

    def update_folder_name_with_title(self, title: str):
        """
        ì œëª©ì„ í¬í•¨í•˜ë„ë¡ í´ë”ëª… ì—…ë°ì´íŠ¸

        Args:
            title: ê²Œì‹œê¸€ ì œëª©
        """
        try:
            # ì œëª© ì •ì œ
            clean_title = self._sanitize_filename(title, max_length=50)

            # ìƒˆ í´ë”ëª… ìƒì„± (ê¸°ì¡´ timestamp ì‚¬ìš©)
            new_dir_name = f"debug_{self.timestamp}_{clean_title}"
            new_debug_dir = self.debug_dir.parent / new_dir_name

            # ê¸°ì¡´ í´ë”ë¥¼ ìƒˆ í´ë”ë¡œ ì´ë™
            if self.debug_dir.exists() and self.debug_dir != new_debug_dir:
                shutil.move(str(self.debug_dir), str(new_debug_dir))
                self.debug_dir = new_debug_dir

                # ë¡œê±°ì˜ íŒŒì¼ í•¸ë“¤ëŸ¬ ì—…ë°ì´íŠ¸
                for handler in self.logger.handlers[:]:
                    if isinstance(handler, logging.FileHandler):
                        handler.close()
                        self.logger.removeHandler(handler)

                # ìƒˆ íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
                log_file = self.debug_dir / "debug.log"
                file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
                file_handler.setLevel(logging.DEBUG)
                formatter = logging.Formatter(
                    '%(asctime)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
                file_handler.setFormatter(formatter)
                self.logger.addHandler(file_handler)

                self.logger.info(f"\nğŸ“ í´ë”ëª… ì—…ë°ì´íŠ¸: {new_dir_name}")

        except Exception as e:
            self.logger.warning(f"í´ë”ëª… ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def start_step(self, step_name: str, description: str):
        """ì²˜ë¦¬ ë‹¨ê³„ ì‹œì‘"""
        self.current_step += 1
        step_num = f"{self.current_step:02d}"

        self.logger.info("\n" + "="*80)
        self.logger.info(f"STEP {step_num}: {step_name}")
        self.logger.info(f"ì„¤ëª…: {description}")
        self.logger.info("="*80)

        self.current_step_data = {
            "step_number": step_num,
            "step_name": step_name,
            "description": description,
            "start_time": datetime.now().isoformat(),
            "input": None,
            "output": None,
            "error": None,
            "success": False
        }

    def log_input(self, input_data: Any, description: str = ""):
        """ì…ë ¥ ë°ì´í„° ë¡œê¹…"""
        self.logger.info(f"\nğŸ“¥ ì…ë ¥ ë°ì´í„°{': ' + description if description else ''}")

        if isinstance(input_data, str):
            self.logger.info(f"  íƒ€ì…: str")
            self.logger.info(f"  ê¸¸ì´: {len(input_data)} ë¬¸ì")
            # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
            display_str = self._truncate_data_uri(input_data, max_length=200)
            if len(input_data) <= 200 or input_data.startswith('data:'):
                self.logger.info(f"  ë‚´ìš©: {display_str}")
            else:
                self.logger.info(f"  ë‚´ìš© (ì²˜ìŒ 200ì): {input_data[:200]}...")
        elif isinstance(input_data, (list, tuple)):
            self.logger.info(f"  íƒ€ì…: {type(input_data).__name__}")
            self.logger.info(f"  ê°œìˆ˜: {len(input_data)}ê°œ")
            if input_data and len(input_data) <= 5:
                for i, item in enumerate(input_data):
                    # ë¦¬ìŠ¤íŠ¸ í•­ëª©ë„ Data URI ì²´í¬
                    if isinstance(item, str):
                        display_item = self._truncate_data_uri(item, max_length=100)
                    else:
                        display_item = str(item)[:100]
                    self.logger.info(f"  [{i}]: {display_item}")
        elif isinstance(input_data, dict):
            self.logger.info(f"  íƒ€ì…: dict")
            self.logger.info(f"  í‚¤: {list(input_data.keys())}")
        else:
            self.logger.info(f"  íƒ€ì…: {type(input_data).__name__}")
            self.logger.info(f"  ê°’: {str(input_data)[:200]}")

        self.current_step_data["input"] = self._serialize(input_data)

    def log_output(self, output_data: Any, description: str = ""):
        """ì¶œë ¥ ë°ì´í„° ë¡œê¹…"""
        self.logger.info(f"\nğŸ“¤ ì¶œë ¥ ë°ì´í„°{': ' + description if description else ''}")

        if isinstance(output_data, str):
            self.logger.info(f"  íƒ€ì…: str")
            self.logger.info(f"  ê¸¸ì´: {len(output_data)} ë¬¸ì")
            # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
            display_str = self._truncate_data_uri(output_data, max_length=200)
            if len(output_data) <= 200 or output_data.startswith('data:'):
                self.logger.info(f"  ë‚´ìš©: {display_str}")
            else:
                self.logger.info(f"  ë‚´ìš© (ì²˜ìŒ 200ì): {output_data[:200]}...")
        elif isinstance(output_data, (list, tuple)):
            self.logger.info(f"  íƒ€ì…: {type(output_data).__name__}")
            self.logger.info(f"  ê°œìˆ˜: {len(output_data)}ê°œ")
            if output_data and len(output_data) <= 5:
                for i, item in enumerate(output_data):
                    # ë¦¬ìŠ¤íŠ¸ í•­ëª©ë„ Data URI ì²´í¬
                    if isinstance(item, str):
                        display_item = self._truncate_data_uri(item, max_length=100)
                    else:
                        display_item = str(item)[:100]
                    self.logger.info(f"  [{i}]: {display_item}")
        elif isinstance(output_data, dict):
            self.logger.info(f"  íƒ€ì…: dict")
            self.logger.info(f"  í‚¤: {list(output_data.keys())}")
            for key, value in output_data.items():
                if isinstance(value, str):
                    # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
                    display_value = self._truncate_data_uri(value, max_length=100)
                    self.logger.info(f"  {key}: {display_value}")
                elif isinstance(value, (list, tuple)):
                    self.logger.info(f"  {key}: [{len(value)}ê°œ í•­ëª©]")
                else:
                    self.logger.info(f"  {key}: {value}")
        else:
            self.logger.info(f"  íƒ€ì…: {type(output_data).__name__}")
            self.logger.info(f"  ê°’: {str(output_data)[:200]}")

        self.current_step_data["output"] = self._serialize(output_data)

    def log_function_call(self, module: str, function: str, args: Dict[str, Any] = None):
        """í•¨ìˆ˜ í˜¸ì¶œ ë¡œê¹…"""
        self.logger.info(f"\nğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ")
        self.logger.info(f"  ëª¨ë“ˆ: {module}")
        self.logger.info(f"  í•¨ìˆ˜: {function}")
        if args:
            self.logger.info(f"  ì¸ì:")
            for key, value in args.items():
                if isinstance(value, str):
                    # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
                    display_value = self._truncate_data_uri(value, max_length=100)
                    self.logger.info(f"    {key}: {display_value}")
                else:
                    self.logger.info(f"    {key}: {value}")

    def end_step(self, success: bool = True, save_to_file: bool = True):
        """ì²˜ë¦¬ ë‹¨ê³„ ì¢…ë£Œ"""
        self.current_step_data["end_time"] = datetime.now().isoformat()
        self.current_step_data["success"] = success

        # íŒŒì¼ë¡œ ì €ì¥
        if save_to_file and self.current_step_data.get("output"):
            step_num = self.current_step_data["step_number"]
            step_name = self.current_step_data["step_name"].replace(" ", "_").lower()

            output_file = self.debug_dir / f"{step_num}_{step_name}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.current_step_data["output"], f, ensure_ascii=False, indent=2)

            self.logger.info(f"\nğŸ’¾ ì¶œë ¥ íŒŒì¼ ì €ì¥: {output_file.name}")

        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        self.logger.info(f"\n{status}: {self.current_step_data['step_name']}")

        self.steps.append(self.current_step_data)

    def log_error(self, error: Exception):
        """ì—ëŸ¬ ë¡œê¹…"""
        error_info = {
            "type": type(error).__name__,
            "message": str(error),
            "traceback": traceback.format_exc()
        }

        self.logger.error(f"\nâŒ ì—ëŸ¬ ë°œìƒ")
        self.logger.error(f"  íƒ€ì…: {error_info['type']}")
        self.logger.error(f"  ë©”ì‹œì§€: {error_info['message']}")
        self.logger.error(f"\nìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{error_info['traceback']}")

        self.current_step_data["error"] = error_info
        self.end_step(success=False)

    def save_raw_html(self, html: str):
        """ì›ë³¸ HTML ì €ì¥"""
        html_file = self.debug_dir / "01_raw_html.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html)
        self.logger.info(f"ğŸ’¾ ì›ë³¸ HTML ì €ì¥: {html_file.name}")

    def generate_summary(self):
        """ì „ì²´ ìš”ì•½ ìƒì„±"""
        summary = {
            "url": self.url,
            "category": self.category,
            "debug_dir": str(self.debug_dir),
            "total_steps": len(self.steps),
            "successful_steps": sum(1 for s in self.steps if s.get("success")),
            "failed_steps": sum(1 for s in self.steps if not s.get("success")),
            "steps": self.steps
        }

        summary_file = self.debug_dir / "summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        self.logger.info("\n" + "="*80)
        self.logger.info("ğŸ“Š ìµœì¢… ìš”ì•½")
        self.logger.info("="*80)
        self.logger.info(f"ì „ì²´ ë‹¨ê³„: {summary['total_steps']}ê°œ")
        self.logger.info(f"ì„±ê³µ: {summary['successful_steps']}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {summary['failed_steps']}ê°œ")
        self.logger.info(f"\nğŸ’¾ ìš”ì•½ íŒŒì¼: {summary_file}")
        self.logger.info(f"ğŸ“ ëª¨ë“  ê²°ê³¼: {self.debug_dir}")
        self.logger.info("="*80)

    def _truncate_data_uri(self, url: str, max_length: int = 100) -> str:
        """
        Data URIë¥¼ ì§§ê²Œ í‘œì‹œ

        Args:
            url: URL ë¬¸ìì—´
            max_length: ìµœëŒ€ ê¸¸ì´ (Data URIê°€ ì•„ë‹Œ ê²½ìš°)

        Returns:
            ì§§ê²Œ í‘œì‹œëœ ë¬¸ìì—´
        """
        if url.startswith('data:'):
            # Data URI í˜•ì‹: data:image/png;base64,iVBORw0KGgo...
            if ';base64,' in url:
                parts = url.split(';base64,')
                mime_type = parts[0].replace('data:', '')
                data_preview = parts[1][:20] if len(parts) > 1 else ''
                total_length = len(parts[1]) if len(parts) > 1 else 0
                return f"data:{mime_type};base64,{data_preview}...({total_length} chars)"
            else:
                return f"{url[:50]}... (Data URI, {len(url)} chars)"
        elif len(url) > max_length:
            return f"{url[:max_length]}..."
        return url

    def _serialize(self, data: Any) -> Any:
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜ (Data URIëŠ” ì§§ê²Œ í‘œì‹œ)"""
        if isinstance(data, str):
            # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
            return self._truncate_data_uri(data)
        elif isinstance(data, (int, float, bool, type(None))):
            return data
        elif isinstance(data, (list, tuple)):
            return [self._serialize(item) for item in data]
        elif isinstance(data, dict):
            return {key: self._serialize(value) for key, value in data.items()}
        else:
            return str(data)


def debug_url(url: str, category: str = "notice"):
    """
    ë‹¨ì¼ URL ë””ë²„ê·¸

    Args:
        url: í¬ë¡¤ë§í•  URL
        category: ì¹´í…Œê³ ë¦¬ (notice, job, seminar)
    """
    tracker = DebugTracker(url, category)

    try:
        # ========== STEP 1: í¬ë¡¤ëŸ¬ ì„ íƒ ==========
        tracker.start_step("í¬ë¡¤ëŸ¬ ì„ íƒ", "ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”")
        tracker.log_input(category, "ì¹´í…Œê³ ë¦¬")

        if category == "notice":
            crawler = NoticeCrawler()
        elif category == "job":
            crawler = JobCrawler()
        elif category == "seminar":
            crawler = SeminarCrawler()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬: {category}")

        tracker.log_output(type(crawler).__name__, "ì´ˆê¸°í™”ëœ í¬ë¡¤ëŸ¬")
        tracker.log_function_call(
            module=f"crawling.{category}_crawler",
            function=f"{category.capitalize()}Crawler.__init__"
        )
        tracker.end_step(save_to_file=False)

        # ========== STEP 2: HTML ë‹¤ìš´ë¡œë“œ ==========
        tracker.start_step("HTML ë‹¤ìš´ë¡œë“œ", "URLì—ì„œ HTML í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ")
        tracker.log_input(url, "URL")
        tracker.log_function_call(
            module="requests",
            function="get",
            args={"url": url}
        )

        import requests
        response = requests.get(url, timeout=30)
        html_content = response.text

        tracker.log_output(html_content, "ë‹¤ìš´ë¡œë“œëœ HTML")
        tracker.save_raw_html(html_content)
        tracker.end_step()

        # ========== STEP 3: HTML íŒŒì‹± (BeautifulSoup) ==========
        tracker.start_step("HTML íŒŒì‹±", "BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ")
        tracker.log_input(html_content[:500], "HTML ë‚´ìš© (ì¼ë¶€)")
        tracker.log_function_call(
            module=f"crawling.{category}_crawler",
            function="extract_from_url",
            args={"url": url}
        )

        # í¬ë¡¤ëŸ¬ì˜ extract_from_url ë©”ì„œë“œ í˜¸ì¶œ
        crawled_data = crawler.extract_from_url(url)

        if crawled_data:
            title, text, image_list, attachment_list, date, crawled_url = crawled_data
            parsed_result = {
                "title": title,
                "text": text[:500] if text else None,
                "text_length": len(text) if text else 0,
                "image_list": image_list,
                "image_count": len(image_list) if image_list else 0,
                "attachment_list": attachment_list,
                "attachment_count": len(attachment_list) if attachment_list else 0,
                "date": date,
                "url": crawled_url
            }
            tracker.log_output(parsed_result, "íŒŒì‹± ê²°ê³¼")
            tracker.end_step()

            # ì œëª©ì„ ì–»ì—ˆìœ¼ë¯€ë¡œ í´ë”ëª… ì—…ë°ì´íŠ¸
            tracker.update_folder_name_with_title(title)
        else:
            tracker.log_error(Exception("í¬ë¡¤ë§ ì‹¤íŒ¨: crawl_pageê°€ None ë°˜í™˜"))
            return

        # ========== STEP 4: í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  ==========
        tracker.start_step("í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• ", "ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• ")
        tracker.log_input({
            "text": text[:200] if text else "",
            "chunk_size": CrawlerConfig.CHUNK_SIZE,
            "chunk_overlap": CrawlerConfig.CHUNK_OVERLAP
        }, "í…ìŠ¤íŠ¸ ë° ì„¤ì •")
        tracker.log_function_call(
            module="processing.document_processor",
            function="CharacterTextSplitter.split_text"
        )

        from processing.document_processor import CharacterTextSplitter
        text_splitter = CharacterTextSplitter(
            chunk_size=CrawlerConfig.CHUNK_SIZE,
            chunk_overlap=CrawlerConfig.CHUNK_OVERLAP
        )

        if text and text.strip():
            text_chunks = text_splitter.split_text(text)
        else:
            text_chunks = []

        chunk_result = {
            "total_chunks": len(text_chunks),
            "chunks": [
                {
                    "index": i,
                    "length": len(chunk),
                    "content": chunk[:200] + "..." if len(chunk) > 200 else chunk
                }
                for i, chunk in enumerate(text_chunks)
            ]
        }
        tracker.log_output(chunk_result, "ì²­í¬ ë¶„í•  ê²°ê³¼")
        tracker.end_step()

        # ========== STEP 5: ë©€í‹°ëª¨ë‹¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ==========
        tracker.start_step("ë©€í‹°ëª¨ë‹¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”", "ì´ë¯¸ì§€ OCR ë° ë¬¸ì„œ íŒŒì‹±ì„ ìœ„í•œ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”")
        tracker.log_function_call(
            module="processing.multimodal_processor",
            function="MultimodalProcessor.__init__"
        )

        mongo_client = MongoClient(CrawlerConfig.MONGODB_URI)
        multimodal_processor = MultimodalProcessor(mongo_client=mongo_client)

        tracker.log_output({
            "enable_image": multimodal_processor.enable_image,
            "enable_attachment": multimodal_processor.enable_attachment
        }, "í”„ë¡œì„¸ì„œ ì„¤ì •")
        tracker.end_step(save_to_file=False)

        # ========== STEP 6: ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ==========
        if image_list:
            tracker.start_step("ì´ë¯¸ì§€ OCR ì²˜ë¦¬", f"{len(image_list)}ê°œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            tracker.log_input(image_list, "ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸")
            tracker.log_function_call(
                module="processing.multimodal_processor",
                function="process_images",
                args={"image_urls": image_list}
            )

            ocr_results = []
            for idx, img_url in enumerate(image_list):
                # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
                url_display = tracker._truncate_data_uri(img_url, max_length=50)
                tracker.logger.info(f"\n  ğŸ–¼ï¸  ì´ë¯¸ì§€ {idx+1}/{len(image_list)}: {url_display}")

                try:
                    # Upstage OCR API í˜¸ì¶œ
                    upstage_client = UpstageClient()
                    ocr_result = upstage_client.extract_text_from_image_url(img_url)

                    if ocr_result and ocr_result.get("text"):
                        ocr_data = {
                            "url": tracker._truncate_data_uri(img_url, max_length=100),  # Data URI ì§§ê²Œ ì €ì¥
                            "url_full": img_url if not img_url.startswith('data:') else "data_uri",  # ì „ì²´ URL (Data URIëŠ” ì œì™¸)
                            "success": True,
                            "text_length": len(ocr_result["text"]),
                            "text_full": ocr_result["text"],  # ì „ì²´ í…ìŠ¤íŠ¸
                            "html_full": ocr_result.get("html", "")  # HTML ì›ë³¸ë„ ì €ì¥
                        }
                        tracker.logger.info(f"     âœ… OCR ì„±ê³µ: {ocr_data['text_length']}ì ì¶”ì¶œ")
                        tracker.logger.info(f"     í…ìŠ¤íŠ¸: {ocr_result['text']}")  # ì „ì²´ í…ìŠ¤íŠ¸ ë¡œê·¸
                    else:
                        ocr_data = {
                            "url": tracker._truncate_data_uri(img_url, max_length=100),  # Data URI ì§§ê²Œ ì €ì¥
                            "url_full": img_url if not img_url.startswith('data:') else "data_uri",
                            "success": False,
                            "error": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                        }
                        tracker.logger.info(f"     âŒ OCR ì‹¤íŒ¨")

                    ocr_results.append(ocr_data)

                except Exception as e:
                    ocr_data = {
                        "url": tracker._truncate_data_uri(img_url, max_length=100),  # Data URI ì§§ê²Œ ì €ì¥
                        "url_full": img_url if not img_url.startswith('data:') else "data_uri",
                        "success": False,
                        "error": str(e)
                    }
                    tracker.logger.error(f"     âŒ OCR ì—ëŸ¬: {e}")
                    ocr_results.append(ocr_data)

            tracker.log_output({
                "total_images": len(image_list),
                "successful": sum(1 for r in ocr_results if r.get("success")),
                "failed": sum(1 for r in ocr_results if not r.get("success")),
                "results": ocr_results
            }, "OCR ì²˜ë¦¬ ê²°ê³¼")
            tracker.end_step()
        else:
            tracker.logger.info("\nâ„¹ï¸  ì´ë¯¸ì§€ê°€ ì—†ì–´ OCR ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # ========== STEP 7: ì²¨ë¶€íŒŒì¼ íŒŒì‹± ==========
        if attachment_list:
            tracker.start_step("ì²¨ë¶€íŒŒì¼ íŒŒì‹±", f"{len(attachment_list)}ê°œ ì²¨ë¶€íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            tracker.log_input(attachment_list, "ì²¨ë¶€íŒŒì¼ URL ë¦¬ìŠ¤íŠ¸")
            tracker.log_function_call(
                module="processing.multimodal_processor",
                function="process_attachments",
                args={"attachment_urls": attachment_list}
            )

            parse_results = []
            for idx, att_url in enumerate(attachment_list):
                # Data URIëŠ” ì§§ê²Œ í‘œì‹œ
                url_display = tracker._truncate_data_uri(att_url, max_length=50)
                tracker.logger.info(f"\n  ğŸ“„ ì²¨ë¶€íŒŒì¼ {idx+1}/{len(attachment_list)}: {url_display}")

                try:
                    # Upstage Document Parse API í˜¸ì¶œ
                    upstage_client = UpstageClient()
                    parse_result = upstage_client.parse_document_from_url(att_url)

                    if parse_result and parse_result.get("text"):
                        parse_data = {
                            "url": tracker._truncate_data_uri(att_url, max_length=100),  # Data URI ì§§ê²Œ ì €ì¥
                            "url_full": att_url if not att_url.startswith('data:') else "data_uri",  # ì „ì²´ URL (Data URIëŠ” ì œì™¸)
                            "success": True,
                            "file_type": Path(att_url).suffix.lower()[1:] if Path(att_url).suffix else "unknown",
                            "text_length": len(parse_result["text"]),
                            "text_full": parse_result["text"],  # ì „ì²´ í…ìŠ¤íŠ¸
                            "html_full": parse_result.get("html", ""),  # HTML ì›ë³¸ë„ ì €ì¥
                            "markdown": parse_result.get("markdown", "")  # Markdown (ìˆìœ¼ë©´)
                        }
                        tracker.logger.info(f"     âœ… íŒŒì‹± ì„±ê³µ: {parse_data['file_type']} - {parse_data['text_length']}ì ì¶”ì¶œ")
                        tracker.logger.info(f"     í…ìŠ¤íŠ¸: {parse_result['text']}")  # ì „ì²´ í…ìŠ¤íŠ¸ ë¡œê·¸
                    else:
                        parse_data = {
                            "url": tracker._truncate_data_uri(att_url, max_length=100),  # Data URI ì§§ê²Œ ì €ì¥
                            "url_full": att_url if not att_url.startswith('data:') else "data_uri",
                            "success": False,
                            "error": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                        }
                        tracker.logger.info(f"     âŒ íŒŒì‹± ì‹¤íŒ¨")

                    parse_results.append(parse_data)

                except Exception as e:
                    parse_data = {
                        "url": tracker._truncate_data_uri(att_url, max_length=100),  # Data URI ì§§ê²Œ ì €ì¥
                        "url_full": att_url if not att_url.startswith('data:') else "data_uri",
                        "success": False,
                        "error": str(e)
                    }
                    tracker.logger.error(f"     âŒ íŒŒì‹± ì—ëŸ¬: {e}")
                    parse_results.append(parse_data)

            tracker.log_output({
                "total_attachments": len(attachment_list),
                "successful": sum(1 for r in parse_results if r.get("success")),
                "failed": sum(1 for r in parse_results if not r.get("success")),
                "results": parse_results
            }, "ë¬¸ì„œ íŒŒì‹± ê²°ê³¼")
            tracker.end_step()
        else:
            tracker.logger.info("\nâ„¹ï¸  ì²¨ë¶€íŒŒì¼ì´ ì—†ì–´ íŒŒì‹± ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # ========== STEP 8: ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ìƒì„± ==========
        tracker.start_step("ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ìƒì„±", "í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì²¨ë¶€íŒŒì¼ ê²°ê³¼ í†µí•©")
        tracker.log_function_call(
            module="processing.multimodal_processor",
            function="create_multimodal_content"
        )

        multimodal_content, failures = multimodal_processor.create_multimodal_content(
            title=title,
            url=url,
            date=date,
            text_chunks=text_chunks,
            image_urls=image_list if image_list else [],
            attachment_urls=attachment_list if attachment_list else []
        )

        content_summary = {
            "title": multimodal_content.title,
            "url": multimodal_content.url,
            "date": multimodal_content.date,
            "text_chunks_count": len(multimodal_content.text_chunks),
            "image_contents_count": len(multimodal_content.image_contents),
            "attachment_contents_count": len(multimodal_content.attachment_contents),
            "failures": {
                "image_failed": len(failures["image_failed"]),
                "image_unsupported": len(failures["image_unsupported"]),
                "attachment_failed": len(failures["attachment_failed"]),
                "attachment_unsupported": len(failures["attachment_unsupported"])
            }
        }
        tracker.log_output(content_summary, "ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸ ")

        # ì‹¤íŒ¨ ê²€ì¦ (document_processor.pyì™€ ë™ì¼í•œ ë¡œì§)
        has_critical_failure = False
        failure_reasons = []

        # ì´ë¯¸ì§€ê°€ ìˆì—ˆëŠ”ë° ì¶”ì¶œ ì‹¤íŒ¨í•œ ê²½ìš°
        if image_list and failures["image_failed"]:
            has_critical_failure = True
            failure_reasons.append(f"ì´ë¯¸ì§€ OCR ì‹¤íŒ¨ {len(failures['image_failed'])}ê°œ")
            tracker.logger.error(f"\nâš ï¸  ê²½ê³ : ì´ë¯¸ì§€ {len(failures['image_failed'])}ê°œ OCR ì‹¤íŒ¨")

        # ì²¨ë¶€íŒŒì¼ì´ ìˆì—ˆëŠ”ë° ì¶”ì¶œ ì‹¤íŒ¨í•œ ê²½ìš°
        if attachment_list and failures["attachment_failed"]:
            has_critical_failure = True
            failure_reasons.append(f"ì²¨ë¶€íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨ {len(failures['attachment_failed'])}ê°œ")
            tracker.logger.error(f"\nâš ï¸  ê²½ê³ : ì²¨ë¶€íŒŒì¼ {len(failures['attachment_failed'])}ê°œ íŒŒì‹± ì‹¤íŒ¨")

        # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì€ ê²½ê³ ë§Œ
        if failures["image_unsupported"]:
            tracker.logger.warning(f"\nâ„¹ï¸  ì´ë¯¸ì§€ {len(failures['image_unsupported'])}ê°œ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹")
        if failures["attachment_unsupported"]:
            tracker.logger.warning(f"\nâ„¹ï¸  ì²¨ë¶€íŒŒì¼ {len(failures['attachment_unsupported'])}ê°œ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹")

        # ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
        if has_critical_failure:
            error_message = " / ".join(failure_reasons)
            tracker.logger.error(f"\nâŒ ê²Œì‹œê¸€ ì²˜ë¦¬ ì‹¤íŒ¨: {error_message}")
            tracker.end_step()
            raise Exception(error_message)

        tracker.end_step()

        # ========== STEP 9: ì„ë² ë”© ì•„ì´í…œ ìƒì„± ==========
        tracker.start_step("ì„ë² ë”© ì•„ì´í…œ ìƒì„±", "Pinecone ì—…ë¡œë“œìš© ìµœì¢… ì•„ì´í…œ ìƒì„±")
        tracker.log_function_call(
            module="processing.multimodal_processor",
            function="MultimodalContent.to_embedding_items"
        )

        embedding_items = multimodal_content.to_embedding_items()

        # ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        for text, metadata in embedding_items:
            metadata["category"] = category

        items_detail = []
        for idx, (text, metadata) in enumerate(embedding_items):
            items_detail.append({
                "index": idx,
                "content_type": metadata.get("content_type"),
                "source": metadata.get("source"),
                "text_length": len(text),
                "text_full": text,  # ì „ì²´ í…ìŠ¤íŠ¸ (preview ì•„ë‹˜!)
                "metadata": metadata
            })

        tracker.log_output({
            "total_items": len(embedding_items),
            "items": items_detail
        }, "ì„ë² ë”© ì•„ì´í…œ")
        tracker.end_step()

        # ìµœì¢… ìš”ì•½ ìƒì„±
        tracker.generate_summary()

    except Exception as e:
        tracker.log_error(e)
        tracker.generate_summary()
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ë‹¨ì¼ URL í¬ë¡¤ë§ ë””ë²„ê·¸ ë„êµ¬")
    parser.add_argument("url", help="í¬ë¡¤ë§í•  URL")
    parser.add_argument("--category", "-c", default="notice",
                       choices=["notice", "job", "seminar"],
                       help="ì¹´í…Œê³ ë¦¬ (ê¸°ë³¸ê°’: notice)")

    args = parser.parse_args()

    debug_url(args.url, args.category)


if __name__ == "__main__":
    main()
