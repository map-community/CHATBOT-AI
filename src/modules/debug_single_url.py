"""
ë‹¨ì¼ URL í¬ë¡¤ë§ ë””ë²„ê·¸ ë„êµ¬

íŠ¹ì • URLì˜ í¬ë¡¤ë§ ì „ ê³¼ì •ì„ ìƒì„¸í•˜ê²Œ ì¶”ì í•˜ê³  ê¸°ë¡í•©ë‹ˆë‹¤.
ê° ì²˜ë¦¬ ë‹¨ê³„ë³„ë¡œ:
- ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ ì €ì¥
- í•¨ìˆ˜ í˜¸ì¶œ íë¦„ ë¡œê¹…
- ì¤‘ê°„ ê²°ê³¼ë¬¼ íŒŒì¼ë¡œ ì €ì¥
- ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ì •ë³´ ê¸°ë¡

ì‚¬ìš©ë²•:
    python debug_single_url.py <URL> [--category <category>]

ì˜ˆì‹œ:
    python debug_single_url.py "https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&wr_id=28848&page=2" --category notice
"""

import sys
import json
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import logging

# modules ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from pymongo import MongoClient
from config import CrawlerConfig
from crawling import NoticeCrawler, JobCrawler, SeminarCrawler
from processing import DocumentProcessor
from processing.multimodal_processor import MultimodalProcessor
from processing.upstage_client import UpstageClient


class DebugTracker:
    """
    ë””ë²„ê·¸ ì¶”ì  í´ë˜ìŠ¤

    ê° ì²˜ë¦¬ ë‹¨ê³„ì˜ ì…ë ¥/ì¶œë ¥ì„ ê¸°ë¡í•˜ê³  íŒŒì¼ë¡œ ì €ì¥
    """

    def __init__(self, url: str, category: str = "notice"):
        self.url = url
        self.category = category

        # ë””ë²„ê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        self.debug_dir = Path("logs/debug") / f"debug_{timestamp}"
        self.debug_dir.mkdir(parents=True, exist_ok=True)

        # ë¡œê±° ì„¤ì •
        self.logger = self._setup_logger()

        # ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥
        self.steps: List[Dict[str, Any]] = []
        self.current_step = 0

        self.logger.info("="*80)
        self.logger.info(f"ğŸ” ë””ë²„ê·¸ ì„¸ì…˜ ì‹œì‘")
        self.logger.info(f"URL: {url}")
        self.logger.info(f"ì¹´í…Œê³ ë¦¬: {category}")
        self.logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.debug_dir}")
        self.logger.info("="*80)

    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("debug_tracker")
        logger.setLevel(logging.DEBUG)
        logger.handlers.clear()

        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_file = self.debug_dir / "debug.log"
        file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)

        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)

        # í¬ë§·
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)

        logger.addHandler(file_handler)
        logger.addHandler(console_handler)

        return logger

    def start_step(self, step_name: str, description: str):
        """ì²˜ë¦¬ ë‹¨ê³„ ì‹œì‘"""
        self.current_step += 1
        step_num = f"{self.current_step:02d}"

        self.logger.info("\n" + "="*80)
        self.logger.info(f"STEP {step_num}: {step_name}")
        self.logger.info(f"ì„¤ëª…: {description}")
        self.logger.info("="*80)

        self.current_step_data = {
            "step_number": step_num,
            "step_name": step_name,
            "description": description,
            "start_time": datetime.now().isoformat(),
            "input": None,
            "output": None,
            "error": None,
            "success": False
        }

    def log_input(self, input_data: Any, description: str = ""):
        """ì…ë ¥ ë°ì´í„° ë¡œê¹…"""
        self.logger.info(f"\nğŸ“¥ ì…ë ¥ ë°ì´í„°{': ' + description if description else ''}")

        if isinstance(input_data, str):
            self.logger.info(f"  íƒ€ì…: str")
            self.logger.info(f"  ê¸¸ì´: {len(input_data)} ë¬¸ì")
            if len(input_data) <= 200:
                self.logger.info(f"  ë‚´ìš©: {input_data}")
            else:
                self.logger.info(f"  ë‚´ìš© (ì²˜ìŒ 200ì): {input_data[:200]}...")
        elif isinstance(input_data, (list, tuple)):
            self.logger.info(f"  íƒ€ì…: {type(input_data).__name__}")
            self.logger.info(f"  ê°œìˆ˜: {len(input_data)}ê°œ")
            if input_data and len(input_data) <= 5:
                for i, item in enumerate(input_data):
                    self.logger.info(f"  [{i}]: {str(item)[:100]}")
        elif isinstance(input_data, dict):
            self.logger.info(f"  íƒ€ì…: dict")
            self.logger.info(f"  í‚¤: {list(input_data.keys())}")
        else:
            self.logger.info(f"  íƒ€ì…: {type(input_data).__name__}")
            self.logger.info(f"  ê°’: {str(input_data)[:200]}")

        self.current_step_data["input"] = self._serialize(input_data)

    def log_output(self, output_data: Any, description: str = ""):
        """ì¶œë ¥ ë°ì´í„° ë¡œê¹…"""
        self.logger.info(f"\nğŸ“¤ ì¶œë ¥ ë°ì´í„°{': ' + description if description else ''}")

        if isinstance(output_data, str):
            self.logger.info(f"  íƒ€ì…: str")
            self.logger.info(f"  ê¸¸ì´: {len(output_data)} ë¬¸ì")
            if len(output_data) <= 200:
                self.logger.info(f"  ë‚´ìš©: {output_data}")
            else:
                self.logger.info(f"  ë‚´ìš© (ì²˜ìŒ 200ì): {output_data[:200]}...")
        elif isinstance(output_data, (list, tuple)):
            self.logger.info(f"  íƒ€ì…: {type(output_data).__name__}")
            self.logger.info(f"  ê°œìˆ˜: {len(output_data)}ê°œ")
            if output_data and len(output_data) <= 5:
                for i, item in enumerate(output_data):
                    self.logger.info(f"  [{i}]: {str(item)[:100]}")
        elif isinstance(output_data, dict):
            self.logger.info(f"  íƒ€ì…: dict")
            self.logger.info(f"  í‚¤: {list(output_data.keys())}")
            for key, value in output_data.items():
                if isinstance(value, str):
                    self.logger.info(f"  {key}: {value[:100] if len(value) > 100 else value}")
                elif isinstance(value, (list, tuple)):
                    self.logger.info(f"  {key}: [{len(value)}ê°œ í•­ëª©]")
                else:
                    self.logger.info(f"  {key}: {value}")
        else:
            self.logger.info(f"  íƒ€ì…: {type(output_data).__name__}")
            self.logger.info(f"  ê°’: {str(output_data)[:200]}")

        self.current_step_data["output"] = self._serialize(output_data)

    def log_function_call(self, module: str, function: str, args: Dict[str, Any] = None):
        """í•¨ìˆ˜ í˜¸ì¶œ ë¡œê¹…"""
        self.logger.info(f"\nğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ")
        self.logger.info(f"  ëª¨ë“ˆ: {module}")
        self.logger.info(f"  í•¨ìˆ˜: {function}")
        if args:
            self.logger.info(f"  ì¸ì:")
            for key, value in args.items():
                if isinstance(value, str) and len(value) > 100:
                    self.logger.info(f"    {key}: {value[:100]}...")
                else:
                    self.logger.info(f"    {key}: {value}")

    def end_step(self, success: bool = True, save_to_file: bool = True):
        """ì²˜ë¦¬ ë‹¨ê³„ ì¢…ë£Œ"""
        self.current_step_data["end_time"] = datetime.now().isoformat()
        self.current_step_data["success"] = success

        # íŒŒì¼ë¡œ ì €ì¥
        if save_to_file and self.current_step_data.get("output"):
            step_num = self.current_step_data["step_number"]
            step_name = self.current_step_data["step_name"].replace(" ", "_").lower()

            output_file = self.debug_dir / f"{step_num}_{step_name}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.current_step_data["output"], f, ensure_ascii=False, indent=2)

            self.logger.info(f"\nğŸ’¾ ì¶œë ¥ íŒŒì¼ ì €ì¥: {output_file.name}")

        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        self.logger.info(f"\n{status}: {self.current_step_data['step_name']}")

        self.steps.append(self.current_step_data)

    def log_error(self, error: Exception):
        """ì—ëŸ¬ ë¡œê¹…"""
        error_info = {
            "type": type(error).__name__,
            "message": str(error),
            "traceback": traceback.format_exc()
        }

        self.logger.error(f"\nâŒ ì—ëŸ¬ ë°œìƒ")
        self.logger.error(f"  íƒ€ì…: {error_info['type']}")
        self.logger.error(f"  ë©”ì‹œì§€: {error_info['message']}")
        self.logger.error(f"\nìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{error_info['traceback']}")

        self.current_step_data["error"] = error_info
        self.end_step(success=False)

    def save_raw_html(self, html: str):
        """ì›ë³¸ HTML ì €ì¥"""
        html_file = self.debug_dir / "01_raw_html.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html)
        self.logger.info(f"ğŸ’¾ ì›ë³¸ HTML ì €ì¥: {html_file.name}")

    def generate_summary(self):
        """ì „ì²´ ìš”ì•½ ìƒì„±"""
        summary = {
            "url": self.url,
            "category": self.category,
            "debug_dir": str(self.debug_dir),
            "total_steps": len(self.steps),
            "successful_steps": sum(1 for s in self.steps if s.get("success")),
            "failed_steps": sum(1 for s in self.steps if not s.get("success")),
            "steps": self.steps
        }

        summary_file = self.debug_dir / "summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        self.logger.info("\n" + "="*80)
        self.logger.info("ğŸ“Š ìµœì¢… ìš”ì•½")
        self.logger.info("="*80)
        self.logger.info(f"ì „ì²´ ë‹¨ê³„: {summary['total_steps']}ê°œ")
        self.logger.info(f"ì„±ê³µ: {summary['successful_steps']}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {summary['failed_steps']}ê°œ")
        self.logger.info(f"\nğŸ’¾ ìš”ì•½ íŒŒì¼: {summary_file}")
        self.logger.info(f"ğŸ“ ëª¨ë“  ê²°ê³¼: {self.debug_dir}")
        self.logger.info("="*80)

    def _serialize(self, data: Any) -> Any:
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        if isinstance(data, (str, int, float, bool, type(None))):
            return data
        elif isinstance(data, (list, tuple)):
            return [self._serialize(item) for item in data]
        elif isinstance(data, dict):
            return {key: self._serialize(value) for key, value in data.items()}
        else:
            return str(data)


def debug_url(url: str, category: str = "notice"):
    """
    ë‹¨ì¼ URL ë””ë²„ê·¸

    Args:
        url: í¬ë¡¤ë§í•  URL
        category: ì¹´í…Œê³ ë¦¬ (notice, job, seminar)
    """
    tracker = DebugTracker(url, category)

    try:
        # ========== STEP 1: í¬ë¡¤ëŸ¬ ì„ íƒ ==========
        tracker.start_step("í¬ë¡¤ëŸ¬ ì„ íƒ", "ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”")
        tracker.log_input(category, "ì¹´í…Œê³ ë¦¬")

        if category == "notice":
            crawler = NoticeCrawler()
        elif category == "job":
            crawler = JobCrawler()
        elif category == "seminar":
            crawler = SeminarCrawler()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬: {category}")

        tracker.log_output(type(crawler).__name__, "ì´ˆê¸°í™”ëœ í¬ë¡¤ëŸ¬")
        tracker.log_function_call(
            module=f"crawling.{category}_crawler",
            function=f"{category.capitalize()}Crawler.__init__"
        )
        tracker.end_step(save_to_file=False)

        # ========== STEP 2: HTML ë‹¤ìš´ë¡œë“œ ==========
        tracker.start_step("HTML ë‹¤ìš´ë¡œë“œ", "URLì—ì„œ HTML í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ")
        tracker.log_input(url, "URL")
        tracker.log_function_call(
            module="requests",
            function="get",
            args={"url": url}
        )

        import requests
        response = requests.get(url, timeout=30)
        html_content = response.text

        tracker.log_output(html_content, "ë‹¤ìš´ë¡œë“œëœ HTML")
        tracker.save_raw_html(html_content)
        tracker.end_step()

        # ========== STEP 3: HTML íŒŒì‹± (BeautifulSoup) ==========
        tracker.start_step("HTML íŒŒì‹±", "BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ")
        tracker.log_input(html_content[:500], "HTML ë‚´ìš© (ì¼ë¶€)")
        tracker.log_function_call(
            module=f"crawling.{category}_crawler",
            function="extract_from_url",
            args={"url": url}
        )

        # í¬ë¡¤ëŸ¬ì˜ extract_from_url ë©”ì„œë“œ í˜¸ì¶œ
        crawled_data = crawler.extract_from_url(url)

        if crawled_data:
            title, text, image_list, attachment_list, date, crawled_url = crawled_data
            parsed_result = {
                "title": title,
                "text": text[:500] if text else None,
                "text_length": len(text) if text else 0,
                "image_list": image_list,
                "image_count": len(image_list) if image_list else 0,
                "attachment_list": attachment_list,
                "attachment_count": len(attachment_list) if attachment_list else 0,
                "date": date,
                "url": crawled_url
            }
            tracker.log_output(parsed_result, "íŒŒì‹± ê²°ê³¼")
            tracker.end_step()
        else:
            tracker.log_error(Exception("í¬ë¡¤ë§ ì‹¤íŒ¨: crawl_pageê°€ None ë°˜í™˜"))
            return

        # ========== STEP 4: í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  ==========
        tracker.start_step("í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• ", "ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• ")
        tracker.log_input({
            "text": text[:200] if text else "",
            "chunk_size": CrawlerConfig.CHUNK_SIZE,
            "chunk_overlap": CrawlerConfig.CHUNK_OVERLAP
        }, "í…ìŠ¤íŠ¸ ë° ì„¤ì •")
        tracker.log_function_call(
            module="processing.document_processor",
            function="CharacterTextSplitter.split_text"
        )

        from processing.document_processor import CharacterTextSplitter
        text_splitter = CharacterTextSplitter(
            chunk_size=CrawlerConfig.CHUNK_SIZE,
            chunk_overlap=CrawlerConfig.CHUNK_OVERLAP
        )

        if text and text.strip():
            text_chunks = text_splitter.split_text(text)
        else:
            text_chunks = []

        chunk_result = {
            "total_chunks": len(text_chunks),
            "chunks": [
                {
                    "index": i,
                    "length": len(chunk),
                    "content": chunk[:200] + "..." if len(chunk) > 200 else chunk
                }
                for i, chunk in enumerate(text_chunks)
            ]
        }
        tracker.log_output(chunk_result, "ì²­í¬ ë¶„í•  ê²°ê³¼")
        tracker.end_step()

        # ========== STEP 5: ë©€í‹°ëª¨ë‹¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ==========
        tracker.start_step("ë©€í‹°ëª¨ë‹¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”", "ì´ë¯¸ì§€ OCR ë° ë¬¸ì„œ íŒŒì‹±ì„ ìœ„í•œ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”")
        tracker.log_function_call(
            module="processing.multimodal_processor",
            function="MultimodalProcessor.__init__"
        )

        mongo_client = MongoClient(CrawlerConfig.MONGODB_URI)
        multimodal_processor = MultimodalProcessor(mongo_client=mongo_client)

        tracker.log_output({
            "enable_image": multimodal_processor.enable_image,
            "enable_attachment": multimodal_processor.enable_attachment
        }, "í”„ë¡œì„¸ì„œ ì„¤ì •")
        tracker.end_step(save_to_file=False)

        # ========== STEP 6: ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ==========
        if image_list:
            tracker.start_step("ì´ë¯¸ì§€ OCR ì²˜ë¦¬", f"{len(image_list)}ê°œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            tracker.log_input(image_list, "ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸")
            tracker.log_function_call(
                module="processing.multimodal_processor",
                function="process_images",
                args={"image_urls": image_list}
            )

            ocr_results = []
            for idx, img_url in enumerate(image_list):
                tracker.logger.info(f"\n  ğŸ–¼ï¸  ì´ë¯¸ì§€ {idx+1}/{len(image_list)}: {img_url}")

                try:
                    # Upstage OCR API í˜¸ì¶œ
                    upstage_client = UpstageClient()
                    ocr_result = upstage_client.extract_text_from_image_url(img_url)

                    if ocr_result and ocr_result.get("text"):
                        ocr_data = {
                            "url": img_url,
                            "success": True,
                            "text_length": len(ocr_result["text"]),
                            "text_preview": ocr_result["text"][:200]
                        }
                        tracker.logger.info(f"     âœ… OCR ì„±ê³µ: {ocr_data['text_length']}ì ì¶”ì¶œ")
                    else:
                        ocr_data = {
                            "url": img_url,
                            "success": False,
                            "error": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                        }
                        tracker.logger.info(f"     âŒ OCR ì‹¤íŒ¨")

                    ocr_results.append(ocr_data)

                except Exception as e:
                    ocr_data = {
                        "url": img_url,
                        "success": False,
                        "error": str(e)
                    }
                    tracker.logger.error(f"     âŒ OCR ì—ëŸ¬: {e}")
                    ocr_results.append(ocr_data)

            tracker.log_output({
                "total_images": len(image_list),
                "successful": sum(1 for r in ocr_results if r.get("success")),
                "failed": sum(1 for r in ocr_results if not r.get("success")),
                "results": ocr_results
            }, "OCR ì²˜ë¦¬ ê²°ê³¼")
            tracker.end_step()
        else:
            tracker.logger.info("\nâ„¹ï¸  ì´ë¯¸ì§€ê°€ ì—†ì–´ OCR ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # ========== STEP 7: ì²¨ë¶€íŒŒì¼ íŒŒì‹± ==========
        if attachment_list:
            tracker.start_step("ì²¨ë¶€íŒŒì¼ íŒŒì‹±", f"{len(attachment_list)}ê°œ ì²¨ë¶€íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            tracker.log_input(attachment_list, "ì²¨ë¶€íŒŒì¼ URL ë¦¬ìŠ¤íŠ¸")
            tracker.log_function_call(
                module="processing.multimodal_processor",
                function="process_attachments",
                args={"attachment_urls": attachment_list}
            )

            parse_results = []
            for idx, att_url in enumerate(attachment_list):
                tracker.logger.info(f"\n  ğŸ“„ ì²¨ë¶€íŒŒì¼ {idx+1}/{len(attachment_list)}: {att_url}")

                try:
                    # Upstage Document Parse API í˜¸ì¶œ
                    upstage_client = UpstageClient()
                    parse_result = upstage_client.parse_document_from_url(att_url)

                    if parse_result and parse_result.get("text"):
                        parse_data = {
                            "url": att_url,
                            "success": True,
                            "file_type": Path(att_url).suffix.lower()[1:] if Path(att_url).suffix else "unknown",
                            "text_length": len(parse_result["text"]),
                            "text_preview": parse_result["text"][:200]
                        }
                        tracker.logger.info(f"     âœ… íŒŒì‹± ì„±ê³µ: {parse_data['file_type']} - {parse_data['text_length']}ì ì¶”ì¶œ")
                    else:
                        parse_data = {
                            "url": att_url,
                            "success": False,
                            "error": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                        }
                        tracker.logger.info(f"     âŒ íŒŒì‹± ì‹¤íŒ¨")

                    parse_results.append(parse_data)

                except Exception as e:
                    parse_data = {
                        "url": att_url,
                        "success": False,
                        "error": str(e)
                    }
                    tracker.logger.error(f"     âŒ íŒŒì‹± ì—ëŸ¬: {e}")
                    parse_results.append(parse_data)

            tracker.log_output({
                "total_attachments": len(attachment_list),
                "successful": sum(1 for r in parse_results if r.get("success")),
                "failed": sum(1 for r in parse_results if not r.get("success")),
                "results": parse_results
            }, "ë¬¸ì„œ íŒŒì‹± ê²°ê³¼")
            tracker.end_step()
        else:
            tracker.logger.info("\nâ„¹ï¸  ì²¨ë¶€íŒŒì¼ì´ ì—†ì–´ íŒŒì‹± ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # ========== STEP 8: ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ìƒì„± ==========
        tracker.start_step("ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ìƒì„±", "í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì²¨ë¶€íŒŒì¼ ê²°ê³¼ í†µí•©")
        tracker.log_function_call(
            module="processing.multimodal_processor",
            function="create_multimodal_content"
        )

        multimodal_content = multimodal_processor.create_multimodal_content(
            title=title,
            url=url,
            date=date,
            text_chunks=text_chunks,
            image_urls=image_list if image_list else [],
            attachment_urls=attachment_list if attachment_list else []
        )

        content_summary = {
            "title": multimodal_content.title,
            "url": multimodal_content.url,
            "date": multimodal_content.date,
            "text_chunks_count": len(multimodal_content.text_chunks),
            "image_contents_count": len(multimodal_content.image_contents),
            "attachment_contents_count": len(multimodal_content.attachment_contents)
        }
        tracker.log_output(content_summary, "ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸ ")
        tracker.end_step()

        # ========== STEP 9: ì„ë² ë”© ì•„ì´í…œ ìƒì„± ==========
        tracker.start_step("ì„ë² ë”© ì•„ì´í…œ ìƒì„±", "Pinecone ì—…ë¡œë“œìš© ìµœì¢… ì•„ì´í…œ ìƒì„±")
        tracker.log_function_call(
            module="processing.multimodal_processor",
            function="MultimodalContent.to_embedding_items"
        )

        embedding_items = multimodal_content.to_embedding_items()

        # ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        for text, metadata in embedding_items:
            metadata["category"] = category

        items_detail = []
        for idx, (text, metadata) in enumerate(embedding_items):
            items_detail.append({
                "index": idx,
                "content_type": metadata.get("content_type"),
                "source": metadata.get("source"),
                "text_length": len(text),
                "text_preview": text[:200],
                "metadata": metadata
            })

        tracker.log_output({
            "total_items": len(embedding_items),
            "items": items_detail
        }, "ì„ë² ë”© ì•„ì´í…œ")
        tracker.end_step()

        # ìµœì¢… ìš”ì•½ ìƒì„±
        tracker.generate_summary()

    except Exception as e:
        tracker.log_error(e)
        tracker.generate_summary()
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ë‹¨ì¼ URL í¬ë¡¤ë§ ë””ë²„ê·¸ ë„êµ¬")
    parser.add_argument("url", help="í¬ë¡¤ë§í•  URL")
    parser.add_argument("--category", "-c", default="notice",
                       choices=["notice", "job", "seminar"],
                       help="ì¹´í…Œê³ ë¦¬ (ê¸°ë³¸ê°’: notice)")

    args = parser.parse_args()

    debug_url(args.url, args.category)


if __name__ == "__main__":
    main()
