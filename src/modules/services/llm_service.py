"""
LLM Service

LLM ê¸°ë°˜ ì‘ì—…(ì‹œê°„ ì˜ë„ íŒŒì‹±, QA Chain ìƒì„±)ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤
"""
import logging
import json
from typing import Optional, Dict, List, Tuple, Any
from datetime import datetime

from langchain.schema import Document
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_upstage import ChatUpstage

logger = logging.getLogger(__name__)


class LLMService:
    """
    LLM ê¸°ë°˜ ì‘ì—… ì„œë¹„ìŠ¤

    Responsibilities:
    - ì‹œê°„ ì˜ë„ íŒŒì‹± (parse_temporal_intent)
    - LLM ê¸°ë°˜ ì‹œê°„ í‘œí˜„ í•´ì„ (rewrite_query_with_llm)
    - QA Chain ìƒì„± (get_answer_from_chain)
    """

    def __init__(self, storage_manager):
        """
        Args:
            storage_manager: StorageManager ì¸ìŠ¤í„´ìŠ¤
        """
        self.storage = storage_manager

    def parse_temporal_intent(
        self,
        query: str,
        current_date: Optional[datetime] = None
    ) -> Optional[Dict]:
        """
        ì§ˆë¬¸ì—ì„œ ì‹œê°„ í‘œí˜„ì„ ê°ì§€í•˜ê³  í•„í„° ì¡°ê±´ì„ ë°˜í™˜

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            current_date: í˜„ì¬ ë‚ ì§œ (ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°)

        Returns:
            dict: {"year": int, "semester": int, "date_from": datetime} ë˜ëŠ” None

        Examples:
            >>> parse_temporal_intent("ì´ë²ˆí•™ê¸° ìˆ˜ê°•ì‹ ì²­")
            {'year': 2024, 'semester': 1}

            >>> parse_temporal_intent("ìµœê·¼ ê³µì§€ì‚¬í•­")
            {'year_from': 2023}
        """
        if current_date is None:
            current_date = datetime.now()

        current_year = current_date.year
        current_month = current_date.month

        # í•œêµ­ í•™ê¸° ê³„ì‚°: 1í•™ê¸°(3-8ì›”), 2í•™ê¸°(9-2ì›”)
        # ë‹¨, 1-2ì›”ì€ ì „ë…„ë„ 2í•™ê¸°ë¡œ ê°„ì£¼
        if 3 <= current_month <= 8:
            current_semester = 1
        else:  # 9-12ì›” ë˜ëŠ” 1-2ì›”
            current_semester = 2
            if current_month <= 2:
                current_year -= 1  # 1-2ì›”ì€ ì „ë…„ë„ 2í•™ê¸°

        # 1ë‹¨ê³„: ê°„ë‹¨í•œ ì‹œê°„ í‘œí˜„ì€ ê·œì¹™ìœ¼ë¡œ ì²˜ë¦¬ (ë¹ ë¥´ê³  ë¹„ìš© 0)
        simple_temporal_keywords = {
            'ì´ë²ˆí•™ê¸°': {'year': current_year, 'semester': current_semester},
            'ì´ë²ˆ í•™ê¸°': {'year': current_year, 'semester': current_semester},
            'ì´ë²ˆí•™ë…„': {'year': current_year, 'semester': current_semester},
            'ì´ë²ˆ í•™ë…„': {'year': current_year, 'semester': current_semester},
            'ì˜¬í•´': {'year': current_year},
            'ê¸ˆë…„': {'year': current_year},
            'ìµœê·¼': {'year_from': current_year - 1},  # ìµœê·¼ 1ë…„
        }

        for keyword, time_filter in simple_temporal_keywords.items():
            if keyword in query:
                logger.info(f"â° ì‹œê°„ í‘œí˜„ ê°ì§€ (ê·œì¹™): '{keyword}' â†’ {time_filter}")
                return time_filter

        # 2ë‹¨ê³„: ëª¨ë“  ì§ˆë¬¸ì„ LLMìœ¼ë¡œ ë¶„ì„ (ì‹œê°„ ì˜ë„ íŒŒì•…)
        # í‚¤ì›Œë“œ ì²´í¬ ì œê±° â†’ ëª¨ë“  ì§ˆë¬¸ì—ì„œ ì‹œê°„ ì˜ë„ ê°ì§€
        # ì˜ˆ: "ì¸í„´ì‹­ ìˆì–´?" â†’ ì•”ë¬µì ìœ¼ë¡œ í˜„ì¬ ì§„í–‰ì¤‘ì¸ ê²ƒì„ ë¬»ëŠ” ê²ƒ
        logger.info(f"ğŸ¤” LLMìœ¼ë¡œ ì‹œê°„ ì˜ë„ ë¶„ì„ ì¤‘...")
        llm_filter = self.rewrite_query_with_llm(query, current_date)
        if llm_filter:
            logger.info(f"âœ¨ LLM ë¶„ì„ ê²°ê³¼: {llm_filter}")
            return llm_filter

        return None

    def rewrite_query_with_llm(
        self,
        query: str,
        current_date: datetime
    ) -> Optional[Dict]:
        """
        LLMì„ ì‚¬ìš©í•´ ë³µì¡í•œ ì‹œê°„ í‘œí˜„ì„ í•´ì„í•˜ê³  í•„í„° ì¡°ê±´ì„ ìƒì„±

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            current_date: í˜„ì¬ ë‚ ì§œ

        Returns:
            dict: {"year": int, "semester": int} ë˜ëŠ” None

        Examples:
            >>> rewrite_query_with_llm("ì‘ë…„ ìˆ˜ê°•ì‹ ì²­", datetime(2024, 3, 1))
            {'year': 2023, 'semester': 1, 'is_ongoing': False, 'is_policy': False}
        """
        from config.prompts import get_temporal_intent_prompt

        current_year = current_date.year
        current_month = current_date.month

        # í˜„ì¬ í•™ê¸° ê³„ì‚°
        if 3 <= current_month <= 8:
            current_semester = 1
        else:
            current_semester = 2
            if current_month <= 2:
                current_year -= 1

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
        prompt_template = get_temporal_intent_prompt()

        # ë™ì  ê°’ ê³„ì‚°
        prev_year = current_year if current_semester == 2 else current_year - 1
        prev_semester = 2 if current_semester == 1 else 1
        last_year = current_year - 1

        # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
        prompt = prompt_template.format(
            current_date=current_date.strftime('%Yë…„ %mì›” %dì¼'),
            current_semester=f"{current_year}í•™ë…„ë„ {current_semester}í•™ê¸°",
            query=query,
            prev_year=prev_year,
            prev_semester=prev_semester,
            last_year=last_year
        )

        try:
            llm = ChatUpstage(api_key=self.storage.upstage_api_key, model="solar-mini")
            response = llm.invoke(prompt)

            # JSON íŒŒì‹±
            result = json.loads(response.content.strip())

            # ë¡œê·¸: LLM ì‘ë‹µ JSON ì „ì²´
            logger.info(f"   ğŸ“‹ LLM ì‘ë‹µ JSON: {json.dumps(result, ensure_ascii=False)}")

            # ë¡œê·¸: LLM ì¶”ë¡  ê³¼ì •
            logger.info(f"   ğŸ’¬ LLM ì‹œê°„ ë¶„ì„: {result.get('reasoning', '')}")

            # âœ… ìƒˆë¡œìš´ í•„ë“œ ì¶”ì¶œ
            is_ongoing = result.get('is_ongoing', False)
            is_policy = result.get('is_policy', False)
            year = result.get('year')
            semester = result.get('semester')

            # í•„í„° ì¡°ê±´ ìƒì„±
            if is_ongoing:
                # "ì§„í–‰ì¤‘" ì˜ë„ ê°ì§€
                logger.info(f"   ğŸ¯ 'ì§„í–‰ì¤‘' ì˜ë„ ê°ì§€ë¨ (is_ongoing=true)")
                return {
                    'type': 'ongoing',
                    'is_ongoing': True,
                    'is_policy': is_policy
                }

            elif year is not None and semester is not None:
                # í•™ê¸° í•„í„° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                logger.info(f"   ğŸ“… í•™ê¸° í•„í„°: {year}í•™ë…„ë„ {semester}í•™ê¸°")
                return {
                    'year': year,
                    'semester': semester,
                    'is_ongoing': False,
                    'is_policy': is_policy
                }

            elif is_policy:
                # ì •ì±… ì§ˆë¬¸ (ì‹œê°„ ë¬´ê´€)
                logger.info(f"   ğŸ“œ ì •ì±… ì§ˆë¬¸ ê°ì§€ (ì‹œê°„ í•„í„° ë¹„í™œì„±í™”)")
                return {
                    'type': 'policy',
                    'is_policy': True,
                    'is_ongoing': False
                }

            else:
                # ì‹œê°„ í‘œí˜„ ì—†ìŒ
                logger.debug(f"   â„¹ï¸  ì‹œê°„ í‘œí˜„ ì—†ìŒ")
                return None

        except Exception as e:
            logger.warning(f"âš ï¸  LLM ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨ (ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±): {e}")
            return None

    def get_answer_from_chain(
        self,
        best_docs: List,
        user_question: str,
        query_noun: List[str],
        temporal_filter: Optional[Dict] = None
    ) -> Tuple[Any, List[Document], str]:
        """
        QA Chain ìƒì„± ë° ê´€ë ¨ ë¬¸ì„œ ì²˜ë¦¬

        Args:
            best_docs: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ [(score, title, date, text, url, html, ...), ...]
            user_question: ì‚¬ìš©ì ì§ˆë¬¸
            query_noun: ì¿¼ë¦¬ ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸
            temporal_filter: ì‹œê°„ í•„í„° (parse_temporal_intent ê²°ê³¼)

        Returns:
            Tuple[Any, List[Document], str]:
                - qa_chain: LangChain QA Chain
                - relevant_docs: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
                - relevant_docs_content: í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´

        Process:
            1. HTML/Markdown ì¤‘ë³µ ì œê±°
            2. Document ê°ì²´ ìƒì„±
            3. í‚¤ì›Œë“œ í•„í„°ë§ (ì—¬ëŸ¬ ê²Œì‹œê¸€ í˜¼ì¬ ì‹œ)
            4. QA Chain ìƒì„±
        """
        from modules.utils.date_utils import get_current_kst as get_korean_time
        from modules.utils.formatter import format_temporal_intent, format_docs

        # âœ… HTML(Markdown) ì¤‘ë³µ ì œê±° - ë¹„ì‹¼ Upstage API ê²°ê³¼ ìµœëŒ€ í™œìš©!
        # ê°™ì€ ì´ë¯¸ì§€ì˜ ì—¬ëŸ¬ ì²­í¬ê°€ ëª¨ë‘ ê°™ì€ Markdownì„ ê°€ì§€ë¯€ë¡œ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©
        seen_htmls = set()
        deduplicated_docs = []
        duplicate_html_count = 0

        # ë””ë²„ê¹…: ì¤‘ë³µ ì œê±° ì „ ë¬¸ì„œ ëª©ë¡
        logger.info(f"   ğŸ“¦ ì¤‘ë³µ ì œê±° ì „: {len(best_docs)}ê°œ ì²­í¬")
        for i, doc in enumerate(best_docs[:10]):  # ì²˜ìŒ 10ê°œë§Œ
            source = doc[7] if len(doc) > 7 else "unknown"
            html_len = len(doc[5]) if len(doc) > 5 and doc[5] else 0
            text_len = len(doc[3])
            logger.info(f"      [{i+1}] {source}: text={text_len}ì, html={html_len}ì")

        for doc in best_docs:
            html = doc[5] if len(doc) > 5 else ""

            # HTMLì´ ìˆê³  ì´ë¯¸ ë³¸ ì  ìˆìœ¼ë©´ ìŠ¤í‚µ (ì¤‘ë³µ Markdown ì œê±°)
            if html and html in seen_htmls:
                duplicate_html_count += 1
                continue

            # ìƒˆë¡œìš´ HTMLì´ê±°ë‚˜ HTMLì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if html:
                seen_htmls.add(html)
            deduplicated_docs.append(doc)

        logger.info(
            f"   ğŸ”„ ì¤‘ë³µ ì œê±° í›„: {len(deduplicated_docs)}ê°œ ì²­í¬ "
            f"({duplicate_html_count}ê°œ Markdown ì¤‘ë³µ ì œê±°)"
        )
        if duplicate_html_count > 0:
            logger.info(f"      ğŸ’¡ ê³ ìœ  Markdown: {len(seen_htmls)}ê°œ (Upstage API ê²°ê³¼ íš¨ìœ¨ì  í™œìš©)")

        # âœ… best_docsì—ì„œ ë©”íƒ€ë°ì´í„° ì§ì ‘ ì¶”ì¶œ (URLë¡œ ë‹¤ì‹œ ì°¾ì§€ ì•ŠìŒ)
        documents = []
        markdown_used = 0
        html_converted = 0
        text_fallback = 0

        for doc in deduplicated_docs:
            score = doc[0]
            title = doc[1]
            date = doc[2]
            text = doc[3]
            url = doc[4]
            # âœ… ë©”íƒ€ë°ì´í„°ë¥¼ tupleì—ì„œ ì§ì ‘ ê°€ì ¸ì˜´ (ë²„ê·¸ ìˆ˜ì •!)
            html = doc[5] if len(doc) > 5 else ""
            content_type = doc[6] if len(doc) > 6 else "text"
            source = doc[7] if len(doc) > 7 else "original_post"
            attachment_type = doc[8] if len(doc) > 8 else ""

            # HTML/Markdown ìš°ì„  ì‚¬ìš© (í‘œ êµ¬ì¡° ë³´ì¡´), ì—†ìœ¼ë©´ text ì‚¬ìš©
            if html:
                from modules.utils.html_parser import is_markdown, html_to_markdown_with_text

                # Markdown í˜•ì‹ ê°ì§€ (Upstage API ì œê³µ, ê³ í’ˆì§ˆ í‘œ êµ¬ì¡°)
                # ì´ë¯¸ Markdownì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í† í° íš¨ìœ¨ì , LLM ìµœì í™”)
                if is_markdown(html):
                    # â‘  Markdown í‘œ í˜•ì‹ (Upstage API ê²°ê³¼)
                    page_content = html
                    markdown_used += 1
                else:
                    # â‘¡ HTML â†’ Markdown ë³€í™˜ (fallback)
                    page_content = html_to_markdown_with_text(html)

                    # ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì›ë³¸ text ì‚¬ìš©
                    if not page_content:
                        page_content = text
                        text_fallback += 1
                    else:
                        html_converted += 1
            else:
                # â‘¢ html ì—†ìŒ â†’ text ì‚¬ìš©
                page_content = text
                text_fallback += 1

            # ë‚ ì§œ íŒŒì‹± (ISO 8601ê³¼ ë ˆê±°ì‹œ í˜•ì‹ ëª¨ë‘ ì§€ì›)
            try:
                if date.startswith("ì‘ì„±ì¼"):
                    doc_date = datetime.strptime(date, 'ì‘ì„±ì¼%y-%m-%d %H:%M')
                else:
                    doc_date = datetime.fromisoformat(date)
            except:
                doc_date = datetime.now()

            # Document ê°ì²´ ìƒì„± (ë©€í‹°ëª¨ë‹¬ ë©”íƒ€ë°ì´í„° í¬í•¨)
            doc_obj = Document(
                page_content=page_content,  # HTML ìš°ì„ , ì—†ìœ¼ë©´ text
                metadata={
                    "title": title,
                    "url": url,
                    "doc_date": doc_date,
                    "score": score,  # âœ… ì ìˆ˜ ì •ë³´ ì¶”ê°€ (ê³„ì¸µì  ì„ íƒì— ì‚¬ìš©)
                    "content_type": content_type,
                    "source": source,
                    "attachment_type": attachment_type,
                    "plain_text": text  # ì›ë³¸ í…ìŠ¤íŠ¸ë„ ë³´ê´€
                }
            )
            documents.append(doc_obj)

        # í´ë°± í†µê³„ ë¡œê·¸
        logger.info(f"   ğŸ“Š ì½˜í…ì¸  ì†ŒìŠ¤ í†µê³„:")
        logger.info(f"      â‘  Markdown (Upstage API): {markdown_used}ê°œ")
        logger.info(f"      â‘¡ HTML â†’ Markdown ë³€í™˜: {html_converted}ê°œ")
        logger.info(f"      â‘¢ Text í´ë°±: {text_fallback}ê°œ")
        logger.info(f"      ì´ {len(documents)}ê°œ ë¬¸ì„œ ìƒì„±")

        # âœ… ê°œì„ ëœ í•„í„°ë§: ê°™ì€ ê²Œì‹œê¸€ì˜ ëª¨ë“  ì²­í¬ vs í‚¤ì›Œë“œ í•„í„°ë§
        # í•µì‹¬ ê°œì„ : ê°™ì€ ê²Œì‹œê¸€ì—ì„œ ìˆ˜ì§‘ëœ ì²­í¬ë“¤ì€ ì´ë¯¸ BM25 + Dense + Rerankerë¡œ ê²€ì¦ë¨
        # â†’ í‚¤ì›Œë“œ í•„í„°ë§ìœ¼ë¡œ ì¤‘ìš” ì •ë³´(ì´ë¦„, í•™ë²ˆ ë“±)ë¥¼ ë‹´ì€ ì²­í¬ê°€ ì œê±°ë˜ëŠ” ë¬¸ì œ í•´ê²°

        # ëª¨ë“  ë¬¸ì„œê°€ ê°™ì€ ê²Œì‹œê¸€ì¸ì§€ í™•ì¸ (ì œëª© ê¸°ì¤€)
        unique_titles = set(doc.metadata.get('title', '') for doc in documents)

        if len(unique_titles) == 1:
            # âœ… ê°™ì€ ê²Œì‹œê¸€ì˜ ì²­í¬ë“¤ â†’ ëª¨ë‘ í¬í•¨ (í‚¤ì›Œë“œ í•„í„°ë§ ìŠ¤í‚µ)
            # ì´ìœ : ì´ë¯¸ ë©€í‹°ìŠ¤í…Œì´ì§€ ê²€ìƒ‰(BM25 + Dense + Reranker)ìœ¼ë¡œ ìµœì  ê²Œì‹œê¸€ ì„ ì • ì™„ë£Œ
            # í•´ë‹¹ ê²Œì‹œê¸€ì˜ ëª¨ë“  ì •ë³´(ë³¸ë¬¸, ì´ë¯¸ì§€ OCR, ì²¨ë¶€íŒŒì¼)ë¥¼ LLMì— ì „ë‹¬í•´ì•¼ ì™„ì „í•œ ë‹µë³€ ê°€ëŠ¥
            logger.info(
                f"   âœ… ê°™ì€ ê²Œì‹œê¸€ ì²­í¬ ê°ì§€ â†’ í‚¤ì›Œë“œ í•„í„°ë§ ìŠ¤í‚µ "
                f"({len(documents)}ê°œ ëª¨ë‘ í¬í•¨)"
            )
            relevant_docs = documents
        else:
            # âŒ ì—¬ëŸ¬ ê²Œì‹œê¸€ í˜¼ì¬ â†’ í‚¤ì›Œë“œ í•„í„°ë§ ì ìš©
            logger.info(f"   ğŸ” ì—¬ëŸ¬ ê²Œì‹œê¸€ í˜¼ì¬ ({len(unique_titles)}ê°œ) â†’ í‚¤ì›Œë“œ í•„í„°ë§ ì ìš©")
            relevant_docs = [
                doc for doc in documents if
                any(keyword in doc.page_content for keyword in query_noun) or  # í‚¤ì›Œë“œ ë§¤ì¹­
                doc.metadata.get('source') in ['image_ocr', 'document_parse']  # ë©€í‹°ëª¨ë‹¬ í•­ìƒ í¬í•¨
            ]

        if not relevant_docs:
            return None, None, None

        # ğŸ” ë””ë²„ê¹…: ê° ì²­í¬ì˜ ë‚´ìš© ê¸¸ì´ í™•ì¸ (ë°ì´í„° ëˆ„ë½ ê²€ì¦)
        logger.info(f"   ğŸ“‹ LLMì— ì „ë‹¬ë  ì²­í¬ ìƒì„¸ (í•„í„°ë§ ì „):")
        for i, doc in enumerate(relevant_docs):
            source = doc.metadata.get('source', 'unknown')
            content_len = len(doc.page_content)
            logger.info(f"      ì²­í¬{i+1}: [{source}] {content_len}ì")

        # âœ… ê³„ì¸µì  í† í° ì œí•œ ì „ëµ (Tiered Token Budget Strategy)
        # Solar Mini: 32,768 í† í° ì œí•œ
        # ì˜ˆì‚° ë°°ë¶„: í”„ë¡¬í”„íŠ¸(~2,000) + ì§ˆë¬¸(~200) + ë‹µë³€(4,096) = ~6,300 í† í°
        # ë¬¸ì„œ ì˜ˆì‚°: 20,000 í† í° (ì•ˆì „ ì—¬ìœ ë¶„ í¬í•¨)
        # í† í° ì¶”ì •: 1 í† í° â‰ˆ 2.5ì (í•œê¸€ ê¸°ì¤€) â†’ 20,000 í† í° â‰ˆ 50,000ì
        MAX_CONTEXT_CHARS = 50000

        # ==========================================
        # Step 1: ë¬¸ì„œë³„ ì ìˆ˜ ë¶„ì„ ë° ê·¸ë£¹ ë¶„ë¥˜
        # ==========================================
        # ë¬¸ì„œë³„ ìµœê³  ì ìˆ˜ ì¶”ì¶œ (ê°™ì€ ë¬¸ì„œì˜ ì—¬ëŸ¬ ì²­í¬ ì¤‘ ìµœê³ ê°’)
        doc_scores = {}
        for doc in relevant_docs:
            title = doc.metadata.get('title', 'Unknown')
            score = doc.metadata.get('score', 0)
            if title not in doc_scores or score > doc_scores[title]:
                doc_scores[title] = score

        # ì ìˆ˜ ê¸°ë°˜ ë¬¸ì„œ ì¤‘ìš”ë„ ë¶„ì„
        if doc_scores:
            sorted_scores = sorted(doc_scores.values(), reverse=True)
            top_score = sorted_scores[0] if sorted_scores else 0

            # ì ìˆ˜ ë¶„í¬ ë¶„ì„
            logger.info(f"   ğŸ“Š ë¬¸ì„œ ì ìˆ˜ ë¶„í¬ ë¶„ì„:")
            logger.info(f"      ë¬¸ì„œ ê°œìˆ˜: {len(doc_scores)}ê°œ")
            for i, (title, score) in enumerate(sorted(doc_scores.items(), key=lambda x: x[1], reverse=True), 1):
                ratio = (score / top_score * 100) if top_score > 0 else 0
                logger.info(f"      {i}ìœ„: {title[:40]}... (ì ìˆ˜: {score:.4f}, ë¹„ìœ¨: {ratio:.1f}%)")

            # ì˜ë¯¸ìˆëŠ” ë¬¸ì„œ ê·¸ë£¹ ì‹ë³„ (Gap Analysis)
            # 1ìœ„ ëŒ€ë¹„ 60% ì´ìƒ ì ìˆ˜ë¥¼ ê°€ì§„ ë¬¸ì„œë¥¼ "ê³ ì ìˆ˜ ê·¸ë£¹"ìœ¼ë¡œ ë¶„ë¥˜
            HIGH_SCORE_THRESHOLD = 0.6  # 1ìœ„ì˜ 60% ì´ìƒ
            high_score_titles = set()

            for title, score in doc_scores.items():
                ratio = (score / top_score) if top_score > 0 else 0
                if ratio >= HIGH_SCORE_THRESHOLD:
                    high_score_titles.add(title)

            logger.info(f"   ğŸ¯ ê³ ì ìˆ˜ ê·¸ë£¹ ì‹ë³„:")
            logger.info(f"      ì„ê³„ê°’: 1ìœ„ì˜ {HIGH_SCORE_THRESHOLD*100:.0f}% ì´ìƒ")
            logger.info(f"      ê³ ì ìˆ˜ ë¬¸ì„œ: {len(high_score_titles)}ê°œ")
            logger.info(f"      ì €ì ìˆ˜ ë¬¸ì„œ: {len(doc_scores) - len(high_score_titles)}ê°œ")
        else:
            high_score_titles = set()
            logger.warning(f"âš ï¸ ë¬¸ì„œ ì ìˆ˜ ì •ë³´ ì—†ìŒ â†’ ëª¨ë“  ë¬¸ì„œë¥¼ ë™ë“±í•˜ê²Œ ì²˜ë¦¬")

        # ==========================================
        # Step 2: ê³„ì¸µì  ì²­í¬ ì„ íƒ (3ë‹¨ê³„)
        # ==========================================
        selected_docs = []
        total_chars = 0

        # Phaseë³„ í†µê³„
        phase_stats = {
            'phase1_added': 0,      # ë³¸ë¬¸ ë³´ì¥
            'phase2_added': 0,      # ê³ ì ìˆ˜ ì´ë¯¸ì§€
            'phase3_added': 0,      # ë‚¨ì€ ì²­í¬
            'phase1_skipped': 0,
            'phase2_skipped': 0,
            'phase3_skipped': 0
        }

        def add_if_fits(doc, phase_key):
            """í† í° ì˜ˆì‚° ë‚´ì—ì„œ ì²­í¬ ì¶”ê°€"""
            nonlocal total_chars
            content_len = len(doc.page_content)

            if total_chars + content_len <= MAX_CONTEXT_CHARS:
                selected_docs.append(doc)
                total_chars += content_len
                phase_stats[f'{phase_key}_added'] += 1
                return True
            else:
                phase_stats[f'{phase_key}_skipped'] += 1
                return False

        logger.info(f"   ğŸ”„ ê³„ì¸µì  ì²­í¬ ì„ íƒ ì‹œì‘:")
        logger.info(f"")

        # ==========================================
        # Phase 1: ëª¨ë“  ë¬¸ì„œì˜ ë³¸ë¬¸ ë³´ì¥ (ìµœìš°ì„ )
        # ==========================================
        logger.info(f"   ğŸ“Œ Phase 1: ëª¨ë“  ë¬¸ì„œì˜ ë³¸ë¬¸ ë³´ì¥")
        original_posts = [doc for doc in relevant_docs if doc.metadata.get('source') == 'original_post']

        for doc in original_posts:
            title = doc.metadata.get('title', 'Unknown')[:40]
            score = doc.metadata.get('score', 0)
            if add_if_fits(doc, 'phase1'):
                logger.info(f"      âœ… [{score:.4f}] {title}... ë³¸ë¬¸ ì¶”ê°€")
            else:
                logger.warning(f"      âš ï¸ [{score:.4f}] {title}... í† í° ë¶€ì¡±ìœ¼ë¡œ ë³¸ë¬¸ ì œì™¸")

        logger.info(f"      â†’ Phase 1 ì™„ë£Œ: {phase_stats['phase1_added']}ê°œ ì¶”ê°€, "
                   f"{phase_stats['phase1_skipped']}ê°œ ì œì™¸, "
                   f"ëˆ„ì : {total_chars:,}ì / {MAX_CONTEXT_CHARS:,}ì")
        logger.info(f"")

        # ==========================================
        # Phase 2: ê³ ì ìˆ˜ ë¬¸ì„œì˜ ì´ë¯¸ì§€ OCR ë³´ì¥
        # ==========================================
        logger.info(f"   ğŸ“Œ Phase 2: ê³ ì ìˆ˜ ë¬¸ì„œì˜ ì´ë¯¸ì§€ OCR ì¶”ê°€")
        logger.info(f"      ëŒ€ìƒ: 1ìœ„ ì ìˆ˜ì˜ {HIGH_SCORE_THRESHOLD*100:.0f}% ì´ìƒ ë¬¸ì„œ")

        # ì´ë¯¸ì§€ OCR ì²­í¬ë¥¼ ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        image_ocrs = [doc for doc in relevant_docs if doc.metadata.get('source') == 'image_ocr']
        image_ocrs_sorted = sorted(image_ocrs, key=lambda d: doc_scores.get(d.metadata.get('title', ''), 0), reverse=True)

        for doc in image_ocrs_sorted:
            title = doc.metadata.get('title', 'Unknown')
            score = doc.metadata.get('score', 0)

            # ê³ ì ìˆ˜ ë¬¸ì„œë§Œ ë³´ì¥
            if title in high_score_titles:
                if add_if_fits(doc, 'phase2'):
                    logger.info(f"      âœ… [{score:.4f}] {title[:40]}... ì´ë¯¸ì§€ OCR ì¶”ê°€")
                else:
                    logger.warning(f"      âš ï¸ [{score:.4f}] {title[:40]}... í† í° ë¶€ì¡±ìœ¼ë¡œ ì´ë¯¸ì§€ ì œì™¸")

        logger.info(f"      â†’ Phase 2 ì™„ë£Œ: {phase_stats['phase2_added']}ê°œ ì¶”ê°€, "
                   f"{phase_stats['phase2_skipped']}ê°œ ì œì™¸, "
                   f"ëˆ„ì : {total_chars:,}ì / {MAX_CONTEXT_CHARS:,}ì")
        logger.info(f"")

        # ==========================================
        # Phase 3: ë‚¨ì€ ì˜ˆì‚°ìœ¼ë¡œ ì €ì ìˆ˜ ì´ë¯¸ì§€ + ì²¨ë¶€íŒŒì¼ ì¶”ê°€
        # ==========================================
        logger.info(f"   ğŸ“Œ Phase 3: ë‚¨ì€ ì˜ˆì‚°ìœ¼ë¡œ ì¶”ê°€ ì²­í¬ ì±„ìš°ê¸°")

        # ì•„ì§ ì„ íƒë˜ì§€ ì•Šì€ ì²­í¬ë“¤ (ì €ì ìˆ˜ ì´ë¯¸ì§€ + ì²¨ë¶€íŒŒì¼)
        remaining_docs = [doc for doc in relevant_docs if doc not in selected_docs]

        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        remaining_sorted = sorted(remaining_docs,
                                 key=lambda d: doc_scores.get(d.metadata.get('title', ''), 0),
                                 reverse=True)

        for doc in remaining_sorted:
            title = doc.metadata.get('title', 'Unknown')[:40]
            score = doc.metadata.get('score', 0)
            source = doc.metadata.get('source', 'unknown')

            if add_if_fits(doc, 'phase3'):
                logger.info(f"      âœ… [{score:.4f}] {title}... [{source}] ì¶”ê°€")
            else:
                # í† í° ë¶€ì¡±ìœ¼ë¡œ ë” ì´ìƒ ì¶”ê°€ ë¶ˆê°€
                break

        logger.info(f"      â†’ Phase 3 ì™„ë£Œ: {phase_stats['phase3_added']}ê°œ ì¶”ê°€, "
                   f"{phase_stats['phase3_skipped']}ê°œ ì œì™¸, "
                   f"ìµœì¢…: {total_chars:,}ì / {MAX_CONTEXT_CHARS:,}ì")
        logger.info(f"")

        # ==========================================
        # ìµœì¢… í†µê³„
        # ==========================================
        logger.info(f"   ğŸ¯ ê³„ì¸µì  ì„ íƒ ìµœì¢… ê²°ê³¼:")
        logger.info(f"      ì „ì²´ ì²­í¬: {len(relevant_docs)}ê°œ")
        logger.info(f"      ì„ íƒëœ ì²­í¬: {len(selected_docs)}ê°œ")
        logger.info(f"         â””â”€ Phase 1 (ë³¸ë¬¸): {phase_stats['phase1_added']}ê°œ")
        logger.info(f"         â””â”€ Phase 2 (ê³ ì ìˆ˜ ì´ë¯¸ì§€): {phase_stats['phase2_added']}ê°œ")
        logger.info(f"         â””â”€ Phase 3 (ì¶”ê°€ ì²­í¬): {phase_stats['phase3_added']}ê°œ")
        logger.info(f"      ì œì™¸ëœ ì²­í¬: {sum([phase_stats['phase1_skipped'], phase_stats['phase2_skipped'], phase_stats['phase3_skipped']])}ê°œ")
        logger.info(f"      ì´ ë¬¸ì ìˆ˜: {total_chars:,}ì (ì œí•œ: {MAX_CONTEXT_CHARS:,}ì)")
        logger.info(f"      ì˜ˆìƒ í† í°: ~{total_chars // 2.5:,.0f} tokens (ì œí•œ: 20,000 tokens)")
        logger.info(f"      í† í° í™œìš©ë¥ : {(total_chars / MAX_CONTEXT_CHARS * 100):.1f}%")

        # ì„ íƒëœ ì²­í¬ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not selected_docs:
            logger.warning(f"âš ï¸ í† í° ì œí•œìœ¼ë¡œ ì„ íƒëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return None, None, None

        # ì„ íƒëœ ì²­í¬ë¡œ êµì²´
        relevant_docs = selected_docs

        # LLM ì´ˆê¸°í™” (ëª…ë‹¨ ì§ˆë¬¸ì„ ìœ„í•œ ì¶©ë¶„í•œ max_tokens ì„¤ì •)
        llm = ChatUpstage(
            api_key=self.storage.upstage_api_key,
            max_tokens=4096  # ê¸´ ëª…ë‹¨ë„ ì™„ì „íˆ ë‚˜ì—´í•  ìˆ˜ ìˆë„ë¡ ì¶©ë¶„í•œ í† í° í™•ë³´
        )
        relevant_docs_content = format_docs(relevant_docs)

        # ğŸ” ë””ë²„ê¹…: ì „ì²´ context í¬ê¸° ë° ë‚´ìš© í™•ì¸
        logger.info(f"   ğŸ“Š ì „ì²´ Context í¬ê¸°: {len(relevant_docs_content)}ì")
        logger.info(f"   ğŸ“„ ì‹¤ì œ ì „ë‹¬ë˜ëŠ” Context ìš”ì•½:")
        logger.info(f"{'='*100}")

        # ê° ì²­í¬ë¥¼ "\n\në¬¸ì„œ ì œëª©:"ìœ¼ë¡œ ë¶„ë¦¬
        chunks = relevant_docs_content.split('\n\në¬¸ì„œ ì œëª©:')

        # âœ… ì²« ë²ˆì§¸ ë¹ˆ ë¬¸ìì—´ ì œê±° í›„ ëª¨ë“  ì²­í¬ í‘œì‹œ
        actual_chunks = []
        for i, chunk in enumerate(chunks):
            if i == 0 and not chunk.strip():
                # ì²« ë²ˆì§¸ ë¹ˆ ì²­í¬ëŠ” ê±´ë„ˆë›°ê¸°
                continue

            # ë¶„ë¦¬ ì‹œ ì œê±°ëœ 'ë¬¸ì„œ ì œëª©:' ë³µì›
            if i > 0:
                chunk = 'ë¬¸ì„œ ì œëª©:' + chunk

            actual_chunks.append(chunk)

        # âœ… ëª¨ë“  ì²­í¬ í‘œì‹œ (ê°œìˆ˜ ì œí•œ ì—†ìŒ)
        logger.info(f"   ì´ {len(actual_chunks)}ê°œ ì²­í¬ë¥¼ LLMì— ì „ë‹¬:")
        logger.info("")

        for idx, chunk in enumerate(actual_chunks, 1):
            chunk_len = len(chunk)

            # ê°œí–‰ ì œê±°í•˜ì—¬ í•œ ì¤„ë¡œ í‘œì‹œ
            chunk_clean = chunk.replace('\n', ' ').replace('\r', ' ')

            if chunk_len <= 200:
                # 200ì ì´í•˜ë©´ ì „ì²´ ì¶œë ¥ (ê°œí–‰ ì œê±°ë¨)
                logger.info(f"   [ì²­í¬ {idx}/{len(actual_chunks)}] {chunk_clean}")
            else:
                # ì• 150ì + ... + ë’¤ 150ì (ê°œí–‰ ì œê±°ë¨)
                preview = chunk_clean[:150] + f' ... ({chunk_len - 300}ì ìƒëµ) ... ' + chunk_clean[-150:]
                logger.info(f"   [ì²­í¬ {idx}/{len(actual_chunks)}] {preview}")

        logger.info("")
        logger.info(f"{'='*100}")

        # QA Prompt Template ìƒì„±
        from config.prompts import get_qa_prompt
        from langchain.prompts import PromptTemplate

        prompt_text = get_qa_prompt()
        PROMPT = PromptTemplate(
            template=prompt_text,
            input_variables=["current_time", "temporal_intent", "context", "question"]
        )

        qa_chain = (
            {
                "current_time": lambda _: get_korean_time().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„"),
                "temporal_intent": lambda _: format_temporal_intent(temporal_filter),
                "context": RunnableLambda(lambda _: relevant_docs_content),
                "question": RunnablePassthrough()
            }
            | PROMPT
            | llm
            | StrOutputParser()
        )

        return qa_chain, relevant_docs, relevant_docs_content
