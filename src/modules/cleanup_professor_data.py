"""
êµìˆ˜/ì§ì› ì •ë³´ ì‚­ì œ ìŠ¤í¬ë¦½íŠ¸

ëª©ì :
- Auto-increment ID â†’ Title hash ID ì „í™˜ì„ ìœ„í•œ ê¸°ì¡´ ë°ì´í„° ì •ë¦¬
- MongoDB, Pinecone, Redisì—ì„œ êµìˆ˜/ì§ì› ì •ë³´ ì „ì²´ ì‚­ì œ

ì‹¤í–‰ ë°©ë²•:
    python cleanup_professor_data.py

ì£¼ì˜:
- ì‚­ì œëœ ë°ì´í„°ëŠ” ë³µêµ¬ ë¶ˆê°€ëŠ¥
- ì‹¤í–‰ ì „ ë°±ì—… ê¶Œì¥
- ì‚­ì œ í›„ í¬ë¡¤ë§ ì¬ì‹¤í–‰ í•„ìš”
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from pymongo import MongoClient
from pinecone import Pinecone
import redis
import os
from config import CrawlerConfig


def cleanup_mongodb():
    """MongoDBì—ì„œ êµìˆ˜/ì§ì› ì •ë³´ ì‚­ì œ"""
    print("\n" + "="*80)
    print("ğŸ—‘ï¸  MongoDB ì •ë¦¬ ì‹œì‘")
    print("="*80)

    try:
        mongo_client = MongoClient(CrawlerConfig.MONGODB_URI)
        db = mongo_client['chatbot_db']
        collection = db['processed_documents']

        # source: "professor_info"ì¸ ë¬¸ì„œ ì‚­ì œ
        # êµìˆ˜ ì •ë³´ëŠ” titleì´ "[êµìˆ˜]", "[ì´ˆë¹™êµìˆ˜]", "[ì§ì›]"ìœ¼ë¡œ ì‹œì‘
        result = collection.delete_many({
            "$or": [
                {"title": {"$regex": "^\\[êµìˆ˜\\]"}},
                {"title": {"$regex": "^\\[ì´ˆë¹™êµìˆ˜\\]"}},
                {"title": {"$regex": "^\\[ì§ì›\\]"}}
            ]
        })

        print(f"âœ… MongoDB ì‚­ì œ ì™„ë£Œ: {result.deleted_count}ê°œ ë¬¸ì„œ")

        # í™•ì¸
        remaining = collection.count_documents({
            "$or": [
                {"title": {"$regex": "^\\[êµìˆ˜\\]"}},
                {"title": {"$regex": "^\\[ì´ˆë¹™êµìˆ˜\\]"}},
                {"title": {"$regex": "^\\[ì§ì›\\]"}}
            ]
        })

        if remaining > 0:
            print(f"âš ï¸  ì”ì—¬ ë¬¸ì„œ: {remaining}ê°œ (ì •ìƒì¼ ìˆ˜ ìˆìŒ)")
        else:
            print(f"âœ… êµìˆ˜/ì§ì› ì •ë³´ ì „ì²´ ì‚­ì œ í™•ì¸")

    except Exception as e:
        print(f"âŒ MongoDB ì •ë¦¬ ì‹¤íŒ¨: {e}")
        raise


def cleanup_pinecone():
    """Pineconeì—ì„œ êµìˆ˜/ì§ì› ì •ë³´ ë²¡í„° ì‚­ì œ"""
    print("\n" + "="*80)
    print("ğŸ—‘ï¸  Pinecone ì •ë¦¬ ì‹œì‘")
    print("="*80)

    try:
        pc = Pinecone(api_key=CrawlerConfig.PINECONE_API_KEY)
        index = pc.Index(CrawlerConfig.PINECONE_INDEX_NAME)

        # source: "professor_info" í•„í„°ë¡œ ì¡°íšŒ í›„ ì‚­ì œ
        # Pineconeì€ delete_by_metadata ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ queryë¡œ ID ì°¾ê¸°

        print("ğŸ” êµìˆ˜/ì§ì› ì •ë³´ ë²¡í„° ê²€ìƒ‰ ì¤‘...")

        # ë”ë¯¸ ë²¡í„°ë¡œ query (metadata filter ì‚¬ìš©)
        results = index.query(
            vector=[0.0] * 4096,  # ë”ë¯¸ ë²¡í„° (dimension ë§ì¶°ì•¼ í•¨)
            filter={"source": {"$eq": "professor_info"}},
            top_k=10000,  # ìµœëŒ€í•œ ë§ì´ ì¡°íšŒ
            include_metadata=True
        )

        vector_ids = [match['id'] for match in results.get('matches', [])]

        if vector_ids:
            print(f"ğŸ“‹ ë°œê²¬ëœ ë²¡í„°: {len(vector_ids)}ê°œ")
            print(f"ğŸ—‘ï¸  ì‚­ì œ ì¤‘...")

            # Pinecone deleteëŠ” ë°°ì¹˜ë¡œ ì²˜ë¦¬ (1000ê°œì”©)
            batch_size = 1000
            for i in range(0, len(vector_ids), batch_size):
                batch = vector_ids[i:i+batch_size]
                index.delete(ids=batch)
                print(f"   ì‚­ì œ: {i+1}~{min(i+batch_size, len(vector_ids))} ({len(batch)}ê°œ)")

            print(f"âœ… Pinecone ì‚­ì œ ì™„ë£Œ: {len(vector_ids)}ê°œ ë²¡í„°")
        else:
            print(f"â„¹ï¸  ì‚­ì œí•  ë²¡í„° ì—†ìŒ (ì´ë¯¸ ì •ë¦¬ë¨)")

    except Exception as e:
        print(f"âŒ Pinecone ì •ë¦¬ ì‹¤íŒ¨: {e}")
        print(f"âš ï¸  ìˆ˜ë™ ì‚­ì œ í•„ìš”í•  ìˆ˜ ìˆìŒ")
        # Pinecone ì˜¤ë¥˜ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰


def cleanup_redis():
    """Redis Pinecone ë©”íƒ€ë°ì´í„° ìºì‹œ ì‚­ì œ"""
    print("\n" + "="*80)
    print("ğŸ—‘ï¸  Redis ìºì‹œ ì •ë¦¬ ì‹œì‘")
    print("="*80)

    try:
        redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST', 'redis'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=False
        )

        # pinecone_metadata ìºì‹œ ì „ì²´ ì‚­ì œ
        # (ì•± ì¬ì‹œì‘ ì‹œ Pineconeì—ì„œ ì¬ë¡œë“œë¨)
        result = redis_client.delete('pinecone_metadata')

        if result:
            print(f"âœ… Redis ìºì‹œ ì‚­ì œ ì™„ë£Œ: pinecone_metadata")
            print(f"â„¹ï¸  ë‹¤ìŒ ì•± ì‹œì‘ ì‹œ Pineconeì—ì„œ ì¬ë¡œë“œë©ë‹ˆë‹¤")
        else:
            print(f"â„¹ï¸  ì‚­ì œí•  ìºì‹œ ì—†ìŒ (ì´ë¯¸ ì •ë¦¬ë¨)")

    except Exception as e:
        print(f"âŒ Redis ì •ë¦¬ ì‹¤íŒ¨: {e}")
        print(f"âš ï¸  ìˆ˜ë™ ì‚­ì œ í•„ìš”: redis-cli DEL pinecone_metadata")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸ§¹ êµìˆ˜/ì§ì› ì •ë³´ ì •ë¦¬ ì‹œì‘")
    print("="*80)
    print("\nâš ï¸  ê²½ê³ : ë‹¤ìŒ ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤:")
    print("   - MongoDB: êµìˆ˜/ì§ì›/ì´ˆë¹™êµìˆ˜ ë¬¸ì„œ")
    print("   - Pinecone: source='professor_info' ë²¡í„°")
    print("   - Redis: pinecone_metadata ìºì‹œ")
    print("\nğŸ’¡ ì´ ì‘ì—…ì€ Title hash ID ì „í™˜ì„ ìœ„í•œ ì‚¬ì „ ì‘ì—…ì…ë‹ˆë‹¤.")
    print("   ì‚­ì œ í›„ í¬ë¡¤ë§ì„ ì¬ì‹¤í–‰í•˜ë©´ ìƒˆ ID ì²´ê³„ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\n")

    response = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")

    if response.lower() != 'yes':
        print("\nâŒ ì‘ì—… ì·¨ì†Œë¨")
        return

    try:
        # 1. MongoDB ì •ë¦¬
        cleanup_mongodb()

        # 2. Pinecone ì •ë¦¬
        cleanup_pinecone()

        # 3. Redis ì •ë¦¬
        cleanup_redis()

        print("\n" + "="*80)
        print("âœ… ëª¨ë“  ì •ë¦¬ ì‘ì—… ì™„ë£Œ!")
        print("="*80)
        print("\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. run_crawler.py ì‹¤í–‰")
        print("   2. êµìˆ˜/ì§ì› ì •ë³´ê°€ ìƒˆ hash IDë¡œ ì €ì¥ë¨")
        print("   3. ì•± ì¬ì‹œì‘ ì‹œ Redis ìºì‹œ ìë™ ìƒì„±\n")

    except Exception as e:
        print("\n" + "="*80)
        print(f"âŒ ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("="*80)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
